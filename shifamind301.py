# -*- coding: utf-8 -*-
"""ShifaMind301.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mynYVGAWlmgKmshE_gyVRBsZbUHwNPwD

# Try 1

## Imports
"""

!pip uninstall -y faiss faiss-gpu faiss-cpu
!pip install faiss-cpu

!pip install torch_geometric

from google.colab import drive
drive.mount('/content/drive')

"""## Pre"""

import os

base_path = '/content/drive/MyDrive/ShifaMind'

print(f"Listing files and directories under: {base_path}")
print("-" * 50)

file_count = 0
dir_count = 0

for root, dirs, files in os.walk(base_path):
    for d in dirs:
        print(f"Directory: {os.path.join(root, d)}")
        dir_count += 1
    for f in files:
        print(f"File: {os.path.join(root, f)}")
        file_count += 1

print("-" * 50)
print(f"Total directories found: {dir_count}")
print(f"Total files found: {file_count}")

"""## p1"""

#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND2 PHASE 1: Concept Bottleneck Model with TOP-50 ICD-10 Labels
================================================================================
Author: Mohammed Sameer Syed
University of Arizona - MS in AI Capstone

CHANGES FROM SHIFAMIND1_P1:
1. ‚úÖ TOP-50 ICD-10 codes computed from MIMIC-IV (icd_version==10)
2. ‚úÖ Fresh artifacts - no reuse of old splits/checkpoints
3. ‚úÖ All outputs to /content/drive/MyDrive/ShifaMind/10_ShifaMind/run_TIMESTAMP/
4. ‚úÖ Builds mimic_dx_data.csv from raw MIMIC-IV files
5. ‚úÖ Fixed concept space (‚â§120 concepts across all Top-50)

Architecture (unchanged):
1. BioClinicalBERT base encoder
2. Multi-head cross-attention with concepts (MULTIPLICATIVE bottleneck)
3. Concept Head (predicts clinical concepts)
4. Diagnosis Head (predicts TOP-50 ICD-10 codes)

Multi-Objective Loss:
L_total = Œª1¬∑L_dx + Œª2¬∑L_align + Œª3¬∑L_concept

Target Metrics:
- Diagnosis F1: >0.75
- Concept F1: >0.70
- Concept Completeness: >0.80

================================================================================
"""

print("="*80)
print("üöÄ SHIFAMIND2 PHASE 1 - TOP-50 ICD-10 LABELS")
print("="*80)

# ============================================================================
# IMPORTS & SETUP
# ============================================================================

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
from sklearn.model_selection import train_test_split
from transformers import (
    AutoTokenizer, AutoModel,
    get_linear_schedule_with_warmup
)

import json
import pickle
import gzip
from pathlib import Path
from tqdm.auto import tqdm
from typing import Dict, List, Tuple
from collections import defaultdict, Counter
import re
from datetime import datetime

# Reproducibility
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nüñ•Ô∏è  Device: {device}")

# ============================================================================
# CONFIGURATION
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  CONFIGURATION")
print("="*80)

# Create timestamped run folder
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
OUTPUT_BASE = BASE_PATH / '10_ShifaMind' / f'run_{timestamp}'

# Run-specific paths
SHARED_DATA_PATH = OUTPUT_BASE / 'shared_data'
CHECKPOINT_PATH = OUTPUT_BASE / 'checkpoints' / 'phase1'
RESULTS_PATH = OUTPUT_BASE / 'results' / 'phase1'
CONCEPT_STORE_PATH = OUTPUT_BASE / 'concept_store'
LOGS_PATH = OUTPUT_BASE / 'logs'

# Create all directories
for path in [SHARED_DATA_PATH, CHECKPOINT_PATH, RESULTS_PATH, CONCEPT_STORE_PATH, LOGS_PATH]:
    path.mkdir(parents=True, exist_ok=True)

print(f"\nüìÅ Run Folder: {OUTPUT_BASE}")
print(f"üìÅ Timestamp: {timestamp}")
print(f"üìÅ Shared Data: {SHARED_DATA_PATH}")
print(f"üìÅ Checkpoints: {CHECKPOINT_PATH}")
print(f"üìÅ Results: {RESULTS_PATH}")
print(f"üìÅ Concept Store: {CONCEPT_STORE_PATH}")

# Raw MIMIC-IV paths
RAW_MIMIC_PATH = BASE_PATH / '01_Raw_Datasets' / 'Extracted' / 'mimic-iv-3.1' / 'mimic-iv-3.1' / 'hosp'
RAW_MIMIC_NOTE_PATH = BASE_PATH / '01_Raw_Datasets' / 'Extracted' / 'mimic-iv-note-2.2' / 'note'

print(f"\nüìÇ MIMIC-IV Hosp: {RAW_MIMIC_PATH}")
print(f"üìÇ MIMIC-IV Note: {RAW_MIMIC_NOTE_PATH}")

# Fixed global concept space (‚â§120 concepts)
# Common medical concepts applicable across multiple diagnoses
GLOBAL_CONCEPTS = [
    # Symptoms
    'fever', 'cough', 'dyspnea', 'pain', 'nausea', 'vomiting', 'diarrhea', 'fatigue',
    'headache', 'dizziness', 'weakness', 'confusion', 'syncope', 'chest', 'abdominal',
    'dysphagia', 'hemoptysis', 'hematuria', 'hematemesis', 'melena', 'jaundice',
    'edema', 'rash', 'pruritus', 'weight', 'anorexia', 'malaise',
    # Vital signs / Physical findings
    'hypotension', 'hypertension', 'tachycardia', 'bradycardia', 'tachypnea', 'hypoxia',
    'fever', 'hypothermia', 'shock', 'altered', 'lethargic', 'obtunded',
    # Organ systems
    'cardiac', 'pulmonary', 'renal', 'hepatic', 'neurologic', 'gastrointestinal',
    'respiratory', 'cardiovascular', 'genitourinary', 'musculoskeletal', 'endocrine',
    'hematologic', 'dermatologic', 'psychiatric',
    # Common conditions
    'infection', 'sepsis', 'pneumonia', 'uti', 'cellulitis', 'meningitis',
    'failure', 'infarction', 'ischemia', 'hemorrhage', 'thrombosis', 'embolism',
    'obstruction', 'perforation', 'rupture', 'stenosis', 'regurgitation',
    'hypertrophy', 'atrophy', 'neoplasm', 'malignancy', 'metastasis',
    # Lab/diagnostic
    'elevated', 'decreased', 'anemia', 'leukocytosis', 'thrombocytopenia',
    'hyperglycemia', 'hypoglycemia', 'acidosis', 'alkalosis', 'hypoxemia',
    'creatinine', 'bilirubin', 'troponin', 'bnp', 'lactate', 'wbc', 'cultures',
    # Imaging/procedures
    'infiltrate', 'consolidation', 'effusion', 'edema', 'cardiomegaly',
    'ultrasound', 'ct', 'mri', 'xray', 'echo', 'ekg',
    # Treatments
    'antibiotics', 'diuretics', 'vasopressors', 'insulin', 'anticoagulation',
    'oxygen', 'ventilation', 'dialysis', 'transfusion', 'surgery'
]

print(f"\nüß† Global Concept Space: {len(GLOBAL_CONCEPTS)} concepts")

# Hyperparameters (same as shifamind1)
LAMBDA_DX = 1.0
LAMBDA_ALIGN = 0.5
LAMBDA_CONCEPT = 0.3

print(f"\n‚öñÔ∏è  Loss Weights:")
print(f"   Œª1 (Diagnosis): {LAMBDA_DX}")
print(f"   Œª2 (Alignment): {LAMBDA_ALIGN}")
print(f"   Œª3 (Concept):   {LAMBDA_CONCEPT}")

# ============================================================================
# STEP 1: COMPUTE TOP-50 ICD-10 CODES FROM MIMIC-IV
# ============================================================================

print("\n" + "="*80)
print("üìä COMPUTING TOP-50 ICD-10 CODES FROM MIMIC-IV")
print("="*80)

def normalize_icd10_code(code):
    """Normalize ICD-10 code: uppercase, remove dots"""
    if pd.isna(code):
        return None
    code_str = str(code).upper().replace('.', '').strip()
    return code_str if code_str else None

print("\n1Ô∏è‚É£ Loading diagnoses_icd.csv.gz...")
diagnoses_path = RAW_MIMIC_PATH / 'diagnoses_icd.csv.gz'
df_diag = pd.read_csv(diagnoses_path, compression='gzip')
print(f"   Loaded {len(df_diag):,} diagnosis records")

# Filter ICD-10 only
df_diag_icd10 = df_diag[df_diag['icd_version'] == 10].copy()
print(f"   ICD-10 records: {len(df_diag_icd10):,}")

# Normalize codes
df_diag_icd10['icd_code_normalized'] = df_diag_icd10['icd_code'].apply(normalize_icd10_code)
df_diag_icd10 = df_diag_icd10.dropna(subset=['icd_code_normalized'])
print(f"   After normalization: {len(df_diag_icd10):,}")

print("\n2Ô∏è‚É£ Loading discharge notes...")
discharge_path = RAW_MIMIC_NOTE_PATH / 'discharge.csv.gz'
df_notes = pd.read_csv(discharge_path, compression='gzip')
print(f"   Loaded {len(df_notes):,} discharge notes")

# Keep only non-empty notes
df_notes = df_notes[df_notes['text'].notna() & (df_notes['text'].str.len() > 100)].copy()
print(f"   Non-empty notes: {len(df_notes):,}")

# Get unique hadm_id with notes
valid_hadm_ids = set(df_notes['hadm_id'].unique())
print(f"   Unique hadm_id with discharge notes: {len(valid_hadm_ids):,}")

print("\n3Ô∏è‚É£ Filtering diagnoses to hadm_id with notes...")
df_diag_icd10 = df_diag_icd10[df_diag_icd10['hadm_id'].isin(valid_hadm_ids)].copy()
print(f"   Diagnoses with notes: {len(df_diag_icd10):,}")

print("\n4Ô∏è‚É£ Computing Top-50 ICD-10 codes by admission frequency...")
# Count unique hadm_id per code (not total occurrences)
code_counts = df_diag_icd10.groupby('icd_code_normalized')['hadm_id'].nunique().sort_values(ascending=False)
print(f"   Total unique ICD-10 codes: {len(code_counts):,}")

# Take top 50
TOP_50_CODES = code_counts.head(50).index.tolist()
TOP_50_COUNTS = code_counts.head(50).values.tolist()

print(f"\n‚úÖ TOP-50 ICD-10 CODES:")
print(f"{'Rank':<6} {'Code':<10} {'Admissions':<12}")
print("-" * 30)
for rank, (code, count) in enumerate(zip(TOP_50_CODES, TOP_50_COUNTS), 1):
    print(f"{rank:<6} {code:<10} {count:<12,}")

# Save Top-50 info
top50_info = {
    'timestamp': timestamp,
    'top_50_codes': TOP_50_CODES,
    'top_50_counts': {code: int(count) for code, count in zip(TOP_50_CODES, TOP_50_COUNTS)},
    'total_unique_codes': len(code_counts),
    'total_icd10_records': len(df_diag_icd10),
    'valid_admissions': len(valid_hadm_ids)
}

with open(SHARED_DATA_PATH / 'top50_icd10_info.json', 'w') as f:
    json.dump(top50_info, f, indent=2)

print(f"\nüíæ Saved Top-50 info to: {SHARED_DATA_PATH / 'top50_icd10_info.json'}")

# ============================================================================
# STEP 2: BUILD MIMIC_DX_DATA.CSV WITH TOP-50 LABELS
# ============================================================================

print("\n" + "="*80)
print("üìä BUILDING mimic_dx_data.csv WITH TOP-50 LABELS")
print("="*80)

print("\n1Ô∏è‚É£ Creating multi-label matrix...")
# For each hadm_id, create binary vector for Top-50 codes
hadm_labels = defaultdict(lambda: [0] * len(TOP_50_CODES))
code_to_idx = {code: idx for idx, code in enumerate(TOP_50_CODES)}

for _, row in tqdm(df_diag_icd10.iterrows(), total=len(df_diag_icd10), desc="Processing diagnoses"):
    hadm_id = row['hadm_id']
    code = row['icd_code_normalized']
    if code in code_to_idx:
        hadm_labels[hadm_id][code_to_idx[code]] = 1

print(f"   Labeled {len(hadm_labels):,} admissions")

print("\n2Ô∏è‚É£ Merging with discharge notes...")
# Merge notes with labels
df_notes_with_labels = df_notes.copy()
df_notes_with_labels['labels'] = df_notes_with_labels['hadm_id'].map(
    lambda x: hadm_labels.get(x, [0] * len(TOP_50_CODES))
)

# Keep only admissions that have at least one Top-50 label
df_notes_with_labels['has_top50'] = df_notes_with_labels['labels'].apply(lambda x: sum(x) > 0)
df_final = df_notes_with_labels[df_notes_with_labels['has_top50']].copy()

print(f"   Admissions with Top-50 labels: {len(df_final):,}")

# Add individual code columns for easier analysis
for idx, code in enumerate(TOP_50_CODES):
    df_final[code] = df_final['labels'].apply(lambda x: x[idx])

print("\n3Ô∏è‚É£ Label distribution:")
label_counts = [df_final[code].sum() for code in TOP_50_CODES]
print(f"   Mean labels per admission: {np.mean([sum(x) for x in df_final['labels']]):.2f}")
print(f"   Median labels per admission: {np.median([sum(x) for x in df_final['labels']]):.0f}")
print(f"\n   Top-10 most frequent codes in dataset:")
top_10_in_dataset = sorted(zip(TOP_50_CODES, label_counts), key=lambda x: x[1], reverse=True)[:10]
for code, count in top_10_in_dataset:
    print(f"      {code}: {count:,} ({count/len(df_final)*100:.1f}%)")

# Save to CSV
mimic_dx_path = OUTPUT_BASE / 'mimic_dx_data_top50.csv'
df_final[['subject_id', 'hadm_id', 'text'] + TOP_50_CODES].to_csv(mimic_dx_path, index=False)
print(f"\nüíæ Saved dataset to: {mimic_dx_path}")
print(f"   Rows: {len(df_final):,}")
print(f"   Columns: {len(df_final.columns)}")

# ============================================================================
# STEP 3: CREATE TRAIN/VAL/TEST SPLITS (FRESH)
# ============================================================================

print("\n" + "="*80)
print("üìä CREATING TRAIN/VAL/TEST SPLITS (FRESH)")
print("="*80)

# Prepare for splitting
df = df_final[['text', 'labels'] + TOP_50_CODES].copy()
df = df.dropna(subset=['text'])

print(f"\nüìä Dataset size: {len(df):,} samples")

# Random split (stratification not feasible with Top-50 multilabel)
# Split: 70% train, 15% val, 15% test
train_idx, temp_idx = train_test_split(
    range(len(df)),
    test_size=0.3,
    random_state=SEED
)
val_idx, test_idx = train_test_split(
    temp_idx,
    test_size=0.5,
    random_state=SEED
)

df_train = df.iloc[train_idx].reset_index(drop=True)
df_val = df.iloc[val_idx].reset_index(drop=True)
df_test = df.iloc[test_idx].reset_index(drop=True)

print(f"\n‚úÖ Splits created:")
print(f"   Train: {len(df_train):,} ({len(df_train)/len(df)*100:.1f}%)")
print(f"   Val:   {len(df_val):,} ({len(df_val)/len(df)*100:.1f}%)")
print(f"   Test:  {len(df_test):,} ({len(df_test)/len(df)*100:.1f}%)")

# Label distribution per split
print(f"\nüìä Label distribution per split:")
for split_name, split_df in [('Train', df_train), ('Val', df_val), ('Test', df_test)]:
    avg_labels = np.mean([sum(x) for x in split_df['labels']])
    total_positives = sum([sum(x) for x in split_df['labels']])
    print(f"   {split_name}: avg={avg_labels:.2f} labels/sample, total={total_positives:,} positive labels")

# Save splits
with open(SHARED_DATA_PATH / 'train_split.pkl', 'wb') as f:
    pickle.dump(df_train, f)
with open(SHARED_DATA_PATH / 'val_split.pkl', 'wb') as f:
    pickle.dump(df_val, f)
with open(SHARED_DATA_PATH / 'test_split.pkl', 'wb') as f:
    pickle.dump(df_test, f)

# Save split info
split_info = {
    'timestamp': timestamp,
    'total_samples': len(df),
    'train_samples': len(df_train),
    'val_samples': len(df_val),
    'test_samples': len(df_test),
    'num_labels': len(TOP_50_CODES),
    'label_codes': TOP_50_CODES,
    'random_seed': SEED
}

with open(SHARED_DATA_PATH / 'split_info.json', 'w') as f:
    json.dump(split_info, f, indent=2)

print(f"\nüíæ Saved splits to: {SHARED_DATA_PATH}")

# ============================================================================
# STEP 4: GENERATE CONCEPT LABELS (KEYWORD-BASED)
# ============================================================================

print("\n" + "="*80)
print("üß† GENERATING CONCEPT LABELS (KEYWORD-BASED)")
print("="*80)

def generate_concept_labels(texts, concepts):
    """Generate binary concept labels based on keyword presence"""
    labels = []
    for text in tqdm(texts, desc="Labeling"):
        text_lower = str(text).lower()
        concept_label = [1 if concept in text_lower else 0 for concept in concepts]
        labels.append(concept_label)
    return np.array(labels)

print(f"\nüîç Using {len(GLOBAL_CONCEPTS)} global concepts")

train_concept_labels = generate_concept_labels(df_train['text'], GLOBAL_CONCEPTS)
val_concept_labels = generate_concept_labels(df_val['text'], GLOBAL_CONCEPTS)
test_concept_labels = generate_concept_labels(df_test['text'], GLOBAL_CONCEPTS)

print(f"\n‚úÖ Concept labels generated:")
print(f"   Shape: {train_concept_labels.shape}")
print(f"   Concepts per sample (train): {train_concept_labels.sum(axis=1).mean():.2f}")

# Save concept labels
np.save(SHARED_DATA_PATH / 'train_concept_labels.npy', train_concept_labels)
np.save(SHARED_DATA_PATH / 'val_concept_labels.npy', val_concept_labels)
np.save(SHARED_DATA_PATH / 'test_concept_labels.npy', test_concept_labels)

# Save concept list
with open(SHARED_DATA_PATH / 'concept_list.json', 'w') as f:
    json.dump(GLOBAL_CONCEPTS, f, indent=2)

print(f"üíæ Saved concept labels to: {SHARED_DATA_PATH}")

# ============================================================================
# ARCHITECTURE: CONCEPT BOTTLENECK (SAME AS SHIFAMIND1)
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  ARCHITECTURE: CONCEPT BOTTLENECK")
print("="*80)

class ConceptBottleneckCrossAttention(nn.Module):
    """Multiplicative concept bottleneck with cross-attention"""
    def __init__(self, hidden_size, num_heads=8, dropout=0.1, layer_idx=1):
        super().__init__()
        self.hidden_size = hidden_size
        self.num_heads = num_heads
        self.head_dim = hidden_size // num_heads
        self.layer_idx = layer_idx

        self.query = nn.Linear(hidden_size, hidden_size)
        self.key = nn.Linear(hidden_size, hidden_size)
        self.value = nn.Linear(hidden_size, hidden_size)
        self.out_proj = nn.Linear(hidden_size, hidden_size)

        self.gate_net = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_size, hidden_size),
            nn.Sigmoid()
        )

        self.dropout = nn.Dropout(dropout)
        self.layer_norm = nn.LayerNorm(hidden_size)

    def forward(self, hidden_states, concept_embeddings, attention_mask=None):
        batch_size, seq_len, _ = hidden_states.shape
        num_concepts = concept_embeddings.shape[0]

        concepts_batch = concept_embeddings.unsqueeze(0).expand(batch_size, -1, -1)

        Q = self.query(hidden_states).view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)
        K = self.key(concepts_batch).view(batch_size, num_concepts, self.num_heads, self.head_dim).transpose(1, 2)
        V = self.value(concepts_batch).view(batch_size, num_concepts, self.num_heads, self.head_dim).transpose(1, 2)

        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.head_dim ** 0.5)
        attn_weights = F.softmax(scores, dim=-1)
        attn_weights = self.dropout(attn_weights)

        context = torch.matmul(attn_weights, V)
        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.hidden_size)
        context = self.out_proj(context)

        pooled_text = hidden_states.mean(dim=1, keepdim=True).expand(-1, seq_len, -1)
        pooled_context = context.mean(dim=1, keepdim=True).expand(-1, seq_len, -1)
        gate_input = torch.cat([pooled_text, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        output = gate * context
        output = self.layer_norm(output)

        return output, attn_weights.mean(dim=1), gate.mean()


class ShifaMind2Phase1(nn.Module):
    """ShifaMind2 Phase 1: Concept Bottleneck with Top-50 ICD-10"""
    def __init__(self, base_model, num_concepts, num_classes, fusion_layers=[9, 11]):
        super().__init__()
        self.base_model = base_model
        self.hidden_size = base_model.config.hidden_size
        self.num_concepts = num_concepts
        self.fusion_layers = fusion_layers

        self.concept_embeddings = nn.Parameter(
            torch.randn(num_concepts, self.hidden_size) * 0.02
        )

        self.fusion_modules = nn.ModuleDict({
            str(layer): ConceptBottleneckCrossAttention(self.hidden_size, layer_idx=layer)
            for layer in fusion_layers
        })

        self.concept_head = nn.Linear(self.hidden_size, num_concepts)
        self.diagnosis_head = nn.Linear(self.hidden_size, num_classes)
        self.dropout = nn.Dropout(0.1)

    def forward(self, input_ids, attention_mask, return_attention=False):
        outputs = self.base_model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            output_hidden_states=True,
            return_dict=True
        )

        hidden_states = outputs.hidden_states
        current_hidden = outputs.last_hidden_state

        attention_maps = {}
        gate_values = []

        for layer_idx in self.fusion_layers:
            if str(layer_idx) in self.fusion_modules:
                layer_hidden = hidden_states[layer_idx]
                fused_hidden, attn, gate = self.fusion_modules[str(layer_idx)](
                    layer_hidden, self.concept_embeddings, attention_mask
                )
                current_hidden = fused_hidden
                gate_values.append(gate.item())

                if return_attention:
                    attention_maps[f'layer_{layer_idx}'] = attn

        cls_hidden = self.dropout(current_hidden[:, 0, :])
        concept_scores = torch.sigmoid(self.concept_head(cls_hidden))
        diagnosis_logits = self.diagnosis_head(cls_hidden)

        result = {
            'logits': diagnosis_logits,
            'concept_scores': concept_scores,
            'hidden_states': current_hidden,
            'cls_hidden': cls_hidden,
            'avg_gate': np.mean(gate_values) if gate_values else 0.0
        }

        if return_attention:
            result['attention_maps'] = attention_maps

        return result


class MultiObjectiveLoss(nn.Module):
    """Multi-objective loss: L_dx + L_align + L_concept"""
    def __init__(self, lambda_dx=1.0, lambda_align=0.5, lambda_concept=0.3):
        super().__init__()
        self.lambda_dx = lambda_dx
        self.lambda_align = lambda_align
        self.lambda_concept = lambda_concept
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, outputs, dx_labels, concept_labels):
        loss_dx = self.bce(outputs['logits'], dx_labels)

        dx_probs = torch.sigmoid(outputs['logits'])
        concept_scores = outputs['concept_scores']
        loss_align = torch.abs(
            dx_probs.unsqueeze(-1) - concept_scores.unsqueeze(1)
        ).mean()

        concept_logits = torch.logit(concept_scores.clamp(1e-7, 1-1e-7))
        loss_concept = self.bce(concept_logits, concept_labels)

        total_loss = (
            self.lambda_dx * loss_dx +
            self.lambda_align * loss_align +
            self.lambda_concept * loss_concept
        )

        components = {
            'total': total_loss.item(),
            'dx': loss_dx.item(),
            'align': loss_align.item(),
            'concept': loss_concept.item()
        }

        return total_loss, components


print("‚úÖ Architecture defined")

# ============================================================================
# DATASET
# ============================================================================

class ConceptDataset(Dataset):
    def __init__(self, texts, labels, concept_labels, tokenizer, max_length=384):
        self.texts = texts
        self.labels = labels
        self.concept_labels = concept_labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            str(self.texts[idx]),
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.FloatTensor(self.labels[idx]),
            'concept_labels': torch.FloatTensor(self.concept_labels[idx])
        }

# ============================================================================
# TRAINING
# ============================================================================

print("\n" + "="*80)
print("üèãÔ∏è  TRAINING PHASE 1")
print("="*80)

tokenizer = AutoTokenizer.from_pretrained("emilyalsentzer/Bio_ClinicalBERT")
base_model = AutoModel.from_pretrained("emilyalsentzer/Bio_ClinicalBERT").to(device)

model = ShifaMind2Phase1(
    base_model,
    num_concepts=len(GLOBAL_CONCEPTS),
    num_classes=len(TOP_50_CODES),
    fusion_layers=[9, 11]
).to(device)

print(f"‚úÖ Model loaded: {sum(p.numel() for p in model.parameters()):,} parameters")
print(f"   Num concepts: {len(GLOBAL_CONCEPTS)}")
print(f"   Num diagnoses: {len(TOP_50_CODES)}")

# Create datasets
train_dataset = ConceptDataset(
    df_train['text'].tolist(),
    df_train['labels'].tolist(),
    train_concept_labels,
    tokenizer
)
val_dataset = ConceptDataset(
    df_val['text'].tolist(),
    df_val['labels'].tolist(),
    val_concept_labels,
    tokenizer
)
test_dataset = ConceptDataset(
    df_test['text'].tolist(),
    df_test['labels'].tolist(),
    test_concept_labels,
    tokenizer
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

print(f"‚úÖ Datasets ready")

# Training setup
criterion = MultiObjectiveLoss(
    lambda_dx=LAMBDA_DX,
    lambda_align=LAMBDA_ALIGN,
    lambda_concept=LAMBDA_CONCEPT
)
optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)

num_epochs = 5
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=len(train_loader) // 2,
    num_training_steps=len(train_loader) * num_epochs
)

best_f1 = 0.0
history = {'train_loss': [], 'val_f1': [], 'concept_f1': []}

# Training loop
for epoch in range(num_epochs):
    print(f"\n{'='*70}\nEpoch {epoch+1}/{num_epochs}\n{'='*70}")

    model.train()
    epoch_losses = defaultdict(list)

    for batch in tqdm(train_loader, desc="Training"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        dx_labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)

        optimizer.zero_grad()
        outputs = model(input_ids, attention_mask)
        loss, components = criterion(outputs, dx_labels, concept_labels)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        scheduler.step()

        for k, v in components.items():
            epoch_losses[k].append(v)

    print(f"\nüìä Epoch {epoch+1} Losses:")
    print(f"   Total:     {np.mean(epoch_losses['total']):.4f}")
    print(f"   Diagnosis: {np.mean(epoch_losses['dx']):.4f}")
    print(f"   Alignment: {np.mean(epoch_losses['align']):.4f}")
    print(f"   Concept:   {np.mean(epoch_losses['concept']):.4f}")

    # Validation
    model.eval()
    all_dx_preds, all_dx_labels = [], []
    all_concept_preds, all_concept_labels = [], []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validating"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            dx_labels = batch['labels'].to(device)
            concept_labels = batch['concept_labels'].to(device)

            outputs = model(input_ids, attention_mask)

            all_dx_preds.append(torch.sigmoid(outputs['logits']).cpu())
            all_dx_labels.append(dx_labels.cpu())
            all_concept_preds.append(outputs['concept_scores'].cpu())
            all_concept_labels.append(concept_labels.cpu())

    all_dx_preds = torch.cat(all_dx_preds, dim=0).numpy()
    all_dx_labels = torch.cat(all_dx_labels, dim=0).numpy()
    all_concept_preds = torch.cat(all_concept_preds, dim=0).numpy()
    all_concept_labels = torch.cat(all_concept_labels, dim=0).numpy()

    dx_pred_binary = (all_dx_preds > 0.5).astype(int)
    concept_pred_binary = (all_concept_preds > 0.5).astype(int)

    dx_f1 = f1_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
    concept_f1 = f1_score(all_concept_labels, concept_pred_binary, average='macro', zero_division=0)

    print(f"\nüìà Validation:")
    print(f"   Diagnosis F1: {dx_f1:.4f}")
    print(f"   Concept F1:   {concept_f1:.4f}")

    history['train_loss'].append(np.mean(epoch_losses['total']))
    history['val_f1'].append(dx_f1)
    history['concept_f1'].append(concept_f1)

    if dx_f1 > best_f1:
        best_f1 = dx_f1
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'macro_f1': best_f1,
            'concept_f1': concept_f1,
            'concept_embeddings': model.concept_embeddings.data.cpu(),
            'num_concepts': model.num_concepts,
            'config': {
                'num_concepts': len(GLOBAL_CONCEPTS),
                'num_classes': len(TOP_50_CODES),
                'fusion_layers': [9, 11],
                'lambda_dx': LAMBDA_DX,
                'lambda_align': LAMBDA_ALIGN,
                'lambda_concept': LAMBDA_CONCEPT,
                'top_50_codes': TOP_50_CODES,
                'timestamp': timestamp
            }
        }
        torch.save(checkpoint, CHECKPOINT_PATH / 'phase1_best.pt')
        print(f"   ‚úÖ Saved best model (F1: {best_f1:.4f})")

print(f"\n‚úÖ Training complete! Best Diagnosis F1: {best_f1:.4f}")

# ============================================================================
# FINAL EVALUATION
# ============================================================================

print("\n" + "="*80)
print("üìä FINAL TEST EVALUATION")
print("="*80)

checkpoint = torch.load(CHECKPOINT_PATH / 'phase1_best.pt', map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_dx_preds, all_dx_labels = [], []
all_concept_preds, all_concept_labels = [], []

with torch.no_grad():
    for batch in tqdm(test_loader, desc="Testing"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        dx_labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)

        outputs = model(input_ids, attention_mask)

        all_dx_preds.append(torch.sigmoid(outputs['logits']).cpu())
        all_dx_labels.append(dx_labels.cpu())
        all_concept_preds.append(outputs['concept_scores'].cpu())
        all_concept_labels.append(concept_labels.cpu())

all_dx_preds = torch.cat(all_dx_preds, dim=0).numpy()
all_dx_labels = torch.cat(all_dx_labels, dim=0).numpy()
all_concept_preds = torch.cat(all_concept_preds, dim=0).numpy()
all_concept_labels = torch.cat(all_concept_labels, dim=0).numpy()

dx_pred_binary = (all_dx_preds > 0.5).astype(int)
concept_pred_binary = (all_concept_preds > 0.5).astype(int)

macro_f1 = f1_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
micro_f1 = f1_score(all_dx_labels, dx_pred_binary, average='micro', zero_division=0)
macro_precision = precision_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
macro_recall = recall_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)

per_class_f1 = [
    f1_score(all_dx_labels[:, i], dx_pred_binary[:, i], zero_division=0)
    for i in range(len(TOP_50_CODES))
]

concept_f1 = f1_score(all_concept_labels, concept_pred_binary, average='macro', zero_division=0)

print("\n" + "="*80)
print("üéâ SHIFAMIND2 PHASE 1 - FINAL RESULTS")
print("="*80)

print("\nüéØ Diagnosis Performance (Top-50 ICD-10):")
print(f"   Macro F1:    {macro_f1:.4f}")
print(f"   Micro F1:    {micro_f1:.4f}")
print(f"   Precision:   {macro_precision:.4f}")
print(f"   Recall:      {macro_recall:.4f}")

print(f"\nüß† Concept Performance:")
print(f"   Concept F1:  {concept_f1:.4f}")

print(f"\nüìä Top-10 Best Performing Diagnoses:")
top_10_best = sorted(zip(TOP_50_CODES, per_class_f1), key=lambda x: x[1], reverse=True)[:10]
for rank, (code, f1) in enumerate(top_10_best, 1):
    count = top50_info['top_50_counts'].get(code, 0)
    print(f"   {rank}. {code}: F1={f1:.4f} (n={count:,})")

print(f"\nüìä Top-10 Worst Performing Diagnoses:")
top_10_worst = sorted(zip(TOP_50_CODES, per_class_f1), key=lambda x: x[1])[:10]
for rank, (code, f1) in enumerate(top_10_worst, 1):
    count = top50_info['top_50_counts'].get(code, 0)
    print(f"   {rank}. {code}: F1={f1:.4f} (n={count:,})")

# Save results
results = {
    'phase': 'ShifaMind2 Phase 1 - Top-50 ICD-10',
    'timestamp': timestamp,
    'run_folder': str(OUTPUT_BASE),
    'diagnosis_metrics': {
        'macro_f1': float(macro_f1),
        'micro_f1': float(micro_f1),
        'precision': float(macro_precision),
        'recall': float(macro_recall),
        'per_class_f1': {code: float(f1) for code, f1 in zip(TOP_50_CODES, per_class_f1)}
    },
    'concept_metrics': {
        'concept_f1': float(concept_f1),
        'num_concepts': len(GLOBAL_CONCEPTS)
    },
    'dataset_info': {
        'num_labels': len(TOP_50_CODES),
        'train_samples': len(df_train),
        'val_samples': len(df_val),
        'test_samples': len(df_test)
    },
    'loss_weights': {
        'lambda_dx': LAMBDA_DX,
        'lambda_align': LAMBDA_ALIGN,
        'lambda_concept': LAMBDA_CONCEPT
    },
    'training_history': history
}

with open(RESULTS_PATH / 'results.json', 'w') as f:
    json.dump(results, f, indent=2)

# Save per-label F1 scores as CSV
per_label_df = pd.DataFrame({
    'icd_code': TOP_50_CODES,
    'f1_score': per_class_f1,
    'train_count': [top50_info['top_50_counts'].get(code, 0) for code in TOP_50_CODES]
})
per_label_df = per_label_df.sort_values('f1_score', ascending=False)
per_label_df.to_csv(RESULTS_PATH / 'per_label_f1.csv', index=False)

print(f"\nüíæ Results saved to: {RESULTS_PATH / 'results.json'}")
print(f"üíæ Per-label F1 saved to: {RESULTS_PATH / 'per_label_f1.csv'}")
print(f"üíæ Best model saved to: {CHECKPOINT_PATH / 'phase1_best.pt'}")

print("\n" + "="*80)
print("‚úÖ SHIFAMIND2 PHASE 1 COMPLETE!")
print("="*80)
print("\nüìç Summary:")
print(f"   ‚úÖ Top-50 ICD-10 codes computed from MIMIC-IV")
print(f"   ‚úÖ Fresh dataset built: {len(df):,} samples")
print(f"   ‚úÖ Fresh train/val/test splits created")
print(f"   ‚úÖ Concept bottleneck model trained")
print(f"   ‚úÖ Macro F1: {macro_f1:.4f} | Micro F1: {micro_f1:.4f}")
print(f"\nüìÅ All artifacts saved to: {OUTPUT_BASE}")
print(f"\nNext: Run shifamind2_p2.py (GraphSAGE) with this run folder")
print("\nAlhamdulillah! ü§≤")

"""## p2"""

#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND2 PHASE 2: GraphSAGE + Concept Linker (Top-50 ICD-10)
================================================================================
Author: Mohammed Sameer Syed
University of Arizona - MS in AI Capstone

CHANGES FROM SHIFAMIND1_P2:
1. ‚úÖ Uses Top-50 ICD-10 codes from Phase 1
2. ‚úÖ Loads from SAME run folder (no new timestamp)
3. ‚úÖ Fresh concept store (no reuse from old runs)
4. ‚úÖ Medical ontology with Top-50 diagnoses
5. ‚úÖ Same 120 global concepts

Architecture:
1. BioClinicalBERT encoder (from Phase 1)
2. GraphSAGE encoder for medical ontology with Top-50 codes
3. Concept Linker for entity recognition
4. Enhanced concept embeddings from knowledge graph
5. Ontology-aware concept bottleneck

Target Metrics:
- Diagnosis F1: >0.75
- Concept F1: >0.75 (improved with ontology)

================================================================================
"""

print("="*80)
print("üöÄ SHIFAMIND2 PHASE 2 - GRAPHSAGE + TOP-50 ONTOLOGY")
print("="*80)

# ============================================================================
# IMPORTS & SETUP
# ============================================================================

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
import torch_geometric
from torch_geometric.nn import SAGEConv
from torch_geometric.data import Data

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score
from transformers import (
    AutoTokenizer, AutoModel,
    get_linear_schedule_with_warmup
)

import json
import pickle
from pathlib import Path
from tqdm.auto import tqdm
from typing import Dict, List, Tuple, Set
from collections import defaultdict
import networkx as nx
import re
import sys

# Reproducibility
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nüñ•Ô∏è  Device: {device}")

# ============================================================================
# CONFIGURATION: LOAD FROM PHASE 1
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  CONFIGURATION: LOADING FROM PHASE 1")
print("="*80)

# Find the most recent Phase 1 run
BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
SHIFAMIND2_BASE = BASE_PATH / '10_ShifaMind'

# List all run folders
run_folders = sorted([d for d in SHIFAMIND2_BASE.glob('run_*') if d.is_dir()], reverse=True)

if not run_folders:
    print("‚ùå No Phase 1 run found! Please run shifamind2_p1.py first.")
    sys.exit(1)

# Use most recent run
OUTPUT_BASE = run_folders[0]
print(f"üìÅ Using run folder: {OUTPUT_BASE.name}")

# Verify Phase 1 checkpoint exists
PHASE1_CHECKPOINT = OUTPUT_BASE / 'checkpoints' / 'phase1' / 'phase1_best.pt'
if not PHASE1_CHECKPOINT.exists():
    print(f"‚ùå Phase 1 checkpoint not found at: {PHASE1_CHECKPOINT}")
    print("   Please run shifamind2_p1.py first.")
    sys.exit(1)

# Load Phase 1 config
checkpoint = torch.load(PHASE1_CHECKPOINT, map_location='cpu', weights_only=False)
phase1_config = checkpoint['config']
TOP_50_CODES = phase1_config['top_50_codes']
timestamp = phase1_config['timestamp']

print(f"‚úÖ Loaded Phase 1 config:")
print(f"   Timestamp: {timestamp}")
print(f"   Top-50 codes: {len(TOP_50_CODES)} diagnoses")
print(f"   Num concepts: {phase1_config['num_concepts']}")

# Paths (same run folder)
SHARED_DATA_PATH = OUTPUT_BASE / 'shared_data'
CHECKPOINT_PATH = OUTPUT_BASE / 'checkpoints' / 'phase2'
RESULTS_PATH = OUTPUT_BASE / 'results' / 'phase2'
CONCEPT_STORE_PATH = OUTPUT_BASE / 'concept_store'

# Create Phase 2 directories
for path in [CHECKPOINT_PATH, RESULTS_PATH, CONCEPT_STORE_PATH]:
    path.mkdir(parents=True, exist_ok=True)

print(f"\nüìÅ Phase 2 Paths:")
print(f"   Checkpoint: {CHECKPOINT_PATH}")
print(f"   Results: {RESULTS_PATH}")
print(f"   Concept Store: {CONCEPT_STORE_PATH}")

# Load concept list
with open(SHARED_DATA_PATH / 'concept_list.json', 'r') as f:
    ALL_CONCEPTS = json.load(f)

print(f"\nüß† Concepts: {len(ALL_CONCEPTS)} clinical concepts")

# GraphSAGE hyperparameters
GRAPH_HIDDEN_DIM = 256
GRAPH_LAYERS = 2
GRAPHSAGE_AGGREGATION = 'mean'

# Training hyperparameters
LAMBDA_DX = 1.0
LAMBDA_ALIGN = 0.5
LAMBDA_CONCEPT = 0.3
LEARNING_RATE = 1e-5
EPOCHS = 3

print(f"\nüï∏Ô∏è  GraphSAGE Config:")
print(f"   Hidden Dim: {GRAPH_HIDDEN_DIM}")
print(f"   Layers: {GRAPH_LAYERS}")
print(f"   Aggregation: {GRAPHSAGE_AGGREGATION}")

# ============================================================================
# BUILD MEDICAL KNOWLEDGE GRAPH (TOP-50 CODES)
# ============================================================================

print("\n" + "="*80)
print("üï∏Ô∏è  BUILDING MEDICAL KNOWLEDGE GRAPH (TOP-50)")
print("="*80)

def build_medical_ontology_top50(top_50_codes, all_concepts):
    """
    Build medical knowledge graph from Top-50 ICD-10 codes and clinical concepts

    Structure:
    - 50 diagnosis nodes (ICD-10 codes)
    - 120 concept nodes (clinical concepts)
    - Edges: concept -> diagnosis (indicates relationship)
    - Hierarchical/co-occurrence edges between diagnoses
    """
    print("\nüìä Building knowledge graph...")

    G = nx.DiGraph()

    # Add diagnosis nodes
    for code in top_50_codes:
        G.add_node(code, node_type='diagnosis')

    # Add concept nodes
    for concept in all_concepts:
        G.add_node(concept, node_type='concept')

    # Build concept-diagnosis edges based on keyword matching
    # (In production, this would use UMLS/SNOMED-CT mappings)
    print("\nüîó Creating concept-diagnosis edges...")

    # Medical domain knowledge: concept -> likely diagnoses
    concept_diagnosis_patterns = {
        # Respiratory
        'pneumonia': ['J', 'J1', 'J18', 'J44', 'J96'],  # Respiratory codes
        'lung': ['J', 'C34'],
        'respiratory': ['J'],
        'dyspnea': ['J', 'I50', 'I25'],
        'cough': ['J'],
        'hypoxia': ['J', 'I50'],

        # Cardiac
        'cardiac': ['I'],
        'heart': ['I'],
        'failure': ['I50'],
        'infarction': ['I21', 'I22', 'I25'],
        'ischemia': ['I', 'G45'],
        'edema': ['I50', 'R60'],

        # Infection/Sepsis
        'sepsis': ['A', 'R65'],
        'infection': ['A', 'B', 'J', 'N39'],
        'fever': ['A', 'R50'],
        'bacteremia': ['A'],

        # Renal
        'renal': ['N'],
        'kidney': ['N'],
        'creatinine': ['N17', 'N18', 'N19'],

        # Metabolic
        'diabetes': ['E', 'E10', 'E11'],
        'hyperglycemia': ['E', 'R73'],
        'hypoglycemia': ['E'],

        # GI
        'gastrointestinal': ['K'],
        'abdominal': ['K', 'R10'],
        'nausea': ['R11'],
        'vomiting': ['R11'],

        # Neuro
        'confusion': ['F', 'R41'],
        'altered': ['F', 'R40', 'R41'],
        'stroke': ['I6', 'G45'],

        # Hematologic
        'anemia': ['D', 'D50', 'D51'],
        'thrombocytopenia': ['D69'],
        'hemorrhage': ['I', 'K', 'R58'],
    }

    edges_added = 0
    for concept in all_concepts:
        concept_lower = concept.lower()
        # Check direct matches
        if concept_lower in concept_diagnosis_patterns:
            patterns = concept_diagnosis_patterns[concept_lower]
            for code in top_50_codes:
                for pattern in patterns:
                    if code.startswith(pattern):
                        G.add_edge(concept, code, edge_type='indicates', weight=1.0)
                        edges_added += 1
                        break

    print(f"   Added {edges_added} concept-diagnosis edges")

    # Add hierarchical relationships between diagnoses
    # Group by ICD-10 chapter (first letter)
    print("\nüîó Creating diagnosis similarity edges...")
    chapter_groups = defaultdict(list)
    for code in top_50_codes:
        chapter = code[0] if code else 'X'
        chapter_groups[chapter].append(code)

    similarity_edges = 0
    for chapter, codes in chapter_groups.items():
        # Codes in same chapter are related
        for i, code1 in enumerate(codes):
            for code2 in codes[i+1:]:
                G.add_edge(code1, code2, edge_type='similar_chapter', weight=0.5)
                G.add_edge(code2, code1, edge_type='similar_chapter', weight=0.5)
                similarity_edges += 2

    print(f"   Added {similarity_edges} diagnosis similarity edges")

    # Add concept similarity edges (common symptom/finding)
    common_symptom_groups = [
        ['fever', 'infection', 'sepsis'],
        ['dyspnea', 'hypoxia', 'respiratory'],
        ['chest', 'cardiac', 'heart'],
        ['pain', 'abdominal'],
        ['confusion', 'altered', 'neurologic'],
    ]

    concept_edges = 0
    for group in common_symptom_groups:
        valid_group = [c for c in group if c in all_concepts]
        for i, c1 in enumerate(valid_group):
            for c2 in valid_group[i+1:]:
                if c1 in G and c2 in G:
                    G.add_edge(c1, c2, edge_type='related_symptom', weight=0.3)
                    G.add_edge(c2, c1, edge_type='related_symptom', weight=0.3)
                    concept_edges += 2

    print(f"   Added {concept_edges} concept similarity edges")

    print(f"\n‚úÖ Knowledge graph built:")
    print(f"   Nodes: {G.number_of_nodes()}")
    print(f"   Edges: {G.number_of_edges()}")
    print(f"   - Diagnosis nodes: {len([n for n in G.nodes if G.nodes[n].get('node_type') == 'diagnosis'])}")
    print(f"   - Concept nodes: {len([n for n in G.nodes if G.nodes[n].get('node_type') == 'concept'])}")

    return G

ontology_graph = build_medical_ontology_top50(TOP_50_CODES, ALL_CONCEPTS)

# Convert NetworkX to PyTorch Geometric format
def nx_to_pyg(G, concept_list):
    """Convert NetworkX graph to PyTorch Geometric Data object"""

    all_nodes = list(G.nodes())
    node_to_idx = {node: idx for idx, node in enumerate(all_nodes)}

    edge_index = []
    edge_attr = []
    for u, v, data in G.edges(data=True):
        edge_index.append([node_to_idx[u], node_to_idx[v]])
        edge_attr.append(data.get('weight', 1.0))

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(-1)

    num_nodes = len(all_nodes)
    x = torch.randn(num_nodes, GRAPH_HIDDEN_DIM)

    node_types = []
    for node in all_nodes:
        if G.nodes[node].get('node_type') == 'diagnosis':
            node_types.append(0)
        else:
            node_types.append(1)
    node_type_mask = torch.tensor(node_types, dtype=torch.long)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
    data.node_type_mask = node_type_mask
    data.node_to_idx = node_to_idx
    data.idx_to_node = {idx: node for node, idx in node_to_idx.items()}

    return data

graph_data = nx_to_pyg(ontology_graph, ALL_CONCEPTS)
print(f"\n‚úÖ Converted to PyTorch Geometric:")
print(f"   Nodes: {graph_data.x.shape[0]}")
print(f"   Edges: {graph_data.edge_index.shape[1]}")
print(f"   Node features: {graph_data.x.shape[1]}")

# Save graph
import pickle as pkl
with open(CONCEPT_STORE_PATH / 'medical_ontology_top50.gpickle', 'wb') as f:
    pkl.dump(ontology_graph, f)

print(f"üíæ Saved ontology to: {CONCEPT_STORE_PATH / 'medical_ontology_top50.gpickle'}")

# ============================================================================
# GRAPHSAGE ENCODER
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  GRAPHSAGE ENCODER")
print("="*80)

class GraphSAGEEncoder(nn.Module):
    """GraphSAGE encoder for learning concept embeddings from medical ontology"""
    def __init__(self, in_channels, hidden_channels, num_layers=2, aggr='mean'):
        super().__init__()

        self.num_layers = num_layers
        self.convs = nn.ModuleList()

        self.convs.append(SAGEConv(in_channels, hidden_channels, aggr=aggr))

        for _ in range(num_layers - 1):
            self.convs.append(SAGEConv(hidden_channels, hidden_channels, aggr=aggr))

        self.dropout = nn.Dropout(0.3)

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < self.num_layers - 1:
                x = F.relu(x)
                x = self.dropout(x)

        return x

graph_encoder = GraphSAGEEncoder(
    in_channels=GRAPH_HIDDEN_DIM,
    hidden_channels=GRAPH_HIDDEN_DIM,
    num_layers=GRAPH_LAYERS,
    aggr=GRAPHSAGE_AGGREGATION
).to(device)

print(f"‚úÖ GraphSAGE encoder initialized")
print(f"   Parameters: {sum(p.numel() for p in graph_encoder.parameters()):,}")

# ============================================================================
# ENHANCED CONCEPT BOTTLENECK (PHASE 1 + GRAPHSAGE)
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  LOADING PHASE 1 + ADDING GRAPHSAGE")
print("="*80)

class ShifaMind2Phase2(nn.Module):
    """
    ShifaMind2 Phase 2: Enhanced with GraphSAGE-enriched concepts (Top-50)

    Architecture:
    1. BioClinicalBERT encoder (from Phase 1)
    2. GraphSAGE encoder for ontology-based concept embeddings
    3. Concept bottleneck with cross-attention
    4. Multi-head outputs (diagnosis Top-50, concepts)
    """
    def __init__(self, base_model, graph_encoder, graph_data, num_concepts, num_diagnoses, hidden_size=768):
        super().__init__()

        self.bert = base_model
        self.graph_encoder = graph_encoder
        self.hidden_size = hidden_size
        self.num_concepts = num_concepts
        self.num_diagnoses = num_diagnoses

        # Store graph data
        self.register_buffer('graph_x', graph_data.x)
        self.register_buffer('graph_edge_index', graph_data.edge_index)
        self.graph_node_to_idx = graph_data.node_to_idx
        self.graph_idx_to_node = graph_data.idx_to_node

        # Concept embedding fusion (combine BERT + GraphSAGE)
        self.concept_fusion = nn.Sequential(
            nn.Linear(hidden_size + GRAPH_HIDDEN_DIM, hidden_size),
            nn.LayerNorm(hidden_size),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        # Cross-attention for concept bottleneck
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        # Gating network (multiplicative bottleneck)
        self.gate_net = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(hidden_size)

        # Output heads
        self.concept_head = nn.Linear(hidden_size, num_concepts)
        self.diagnosis_head = nn.Linear(hidden_size, num_diagnoses)

    def get_graph_concept_embeddings(self, concept_indices):
        """Get GraphSAGE embeddings for specific concepts"""
        graph_embeddings = self.graph_encoder(self.graph_x, self.graph_edge_index)

        concept_embeds = []
        for concept in ALL_CONCEPTS:
            if concept in self.graph_node_to_idx:
                idx = self.graph_node_to_idx[concept]
                concept_embeds.append(graph_embeddings[idx])
            else:
                concept_embeds.append(torch.zeros(GRAPH_HIDDEN_DIM, device=self.graph_x.device))

        return torch.stack(concept_embeds)

    def forward(self, input_ids, attention_mask, concept_embeddings_bert):
        """
        Forward pass with GraphSAGE-enhanced concepts

        Args:
            input_ids: [batch, seq_len]
            attention_mask: [batch, seq_len]
            concept_embeddings_bert: [num_concepts, hidden_size]
        """
        batch_size = input_ids.shape[0]

        # 1. Encode text with BERT
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state

        # 2. Get GraphSAGE concept embeddings
        graph_concept_embeds = self.get_graph_concept_embeddings(None)

        # 3. Fuse BERT + GraphSAGE concept embeddings
        bert_concepts = concept_embeddings_bert.unsqueeze(0).expand(batch_size, -1, -1)
        graph_concepts = graph_concept_embeds.unsqueeze(0).expand(batch_size, -1, -1)

        fused_input = torch.cat([bert_concepts, graph_concepts], dim=-1)
        enhanced_concepts = self.concept_fusion(fused_input)

        # 4. Cross-attention: text attends to enhanced concepts
        context, attn_weights = self.cross_attention(
            query=hidden_states,
            key=enhanced_concepts,
            value=enhanced_concepts,
            need_weights=True
        )

        # 5. Multiplicative bottleneck gating
        pooled_text = hidden_states.mean(dim=1)
        pooled_context = context.mean(dim=1)

        gate_input = torch.cat([pooled_text, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        # 6. Output heads
        concept_logits = self.concept_head(pooled_text)
        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        return {
            'logits': diagnosis_logits,
            'concept_logits': concept_logits,
            'concept_scores': torch.sigmoid(concept_logits),
            'gate_values': gate,
            'attention_weights': attn_weights,
            'bottleneck_output': bottleneck_output
        }

# Initialize model
print("\nüîß Initializing BioClinicalBERT...")
tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')
base_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT').to(device)

concept_embedding_layer = nn.Embedding(len(ALL_CONCEPTS), 768).to(device)

model = ShifaMind2Phase2(
    base_model=base_model,
    graph_encoder=graph_encoder,
    graph_data=graph_data,
    num_concepts=len(ALL_CONCEPTS),
    num_diagnoses=len(TOP_50_CODES),
    hidden_size=768
).to(device)

# Load Phase 1 weights if available
print(f"\nüì• Loading Phase 1 checkpoint...")
checkpoint = torch.load(PHASE1_CHECKPOINT, map_location=device, weights_only=False)
try:
    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
    print("‚úÖ Loaded Phase 1 weights (partial)")
except Exception as e:
    print(f"‚ö†Ô∏è  Could not load Phase 1 weights: {e}")

print(f"\n‚úÖ ShifaMind2 Phase 2 model initialized")
print(f"   Total parameters: {sum(p.numel() for p in model.parameters()):,}")

# ============================================================================
# TRAINING SETUP
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  TRAINING SETUP")
print("="*80)

# Load data splits from Phase 1
with open(SHARED_DATA_PATH / 'train_split.pkl', 'rb') as f:
    df_train = pickle.load(f)
with open(SHARED_DATA_PATH / 'val_split.pkl', 'rb') as f:
    df_val = pickle.load(f)
with open(SHARED_DATA_PATH / 'test_split.pkl', 'rb') as f:
    df_test = pickle.load(f)

train_concept_labels = np.load(SHARED_DATA_PATH / 'train_concept_labels.npy')
val_concept_labels = np.load(SHARED_DATA_PATH / 'val_concept_labels.npy')
test_concept_labels = np.load(SHARED_DATA_PATH / 'test_concept_labels.npy')

print(f"\n‚úÖ Loaded data splits:")
print(f"   Train: {len(df_train):,}")
print(f"   Val: {len(df_val):,}")
print(f"   Test: {len(df_test):,}")

# Dataset class
class ConceptDataset(Dataset):
    def __init__(self, texts, labels, tokenizer, concept_labels):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.concept_labels = concept_labels

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            str(self.texts[idx]),
            truncation=True,
            max_length=512,
            padding='max_length',
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.tensor(self.labels[idx], dtype=torch.float),
            'concept_labels': torch.tensor(self.concept_labels[idx], dtype=torch.float)
        }

train_dataset = ConceptDataset(df_train['text'].tolist(), df_train['labels'].tolist(), tokenizer, train_concept_labels)
val_dataset = ConceptDataset(df_val['text'].tolist(), df_val['labels'].tolist(), tokenizer, val_concept_labels)
test_dataset = ConceptDataset(df_test['text'].tolist(), df_test['labels'].tolist(), tokenizer, test_concept_labels)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
total_steps = len(train_loader) * EPOCHS
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)

# Loss function
class MultiObjectiveLoss(nn.Module):
    def __init__(self, lambda_dx, lambda_align, lambda_concept):
        super().__init__()
        self.lambda_dx = lambda_dx
        self.lambda_align = lambda_align
        self.lambda_concept = lambda_concept
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, outputs, dx_labels, concept_labels):
        loss_dx = self.bce(outputs['logits'], dx_labels)

        dx_probs = torch.sigmoid(outputs['logits'])
        concept_scores = outputs['concept_scores']
        loss_align = torch.abs(dx_probs.unsqueeze(-1) - concept_scores.unsqueeze(1)).mean()

        loss_concept = self.bce(outputs['concept_logits'], concept_labels)

        total_loss = (
            self.lambda_dx * loss_dx +
            self.lambda_align * loss_align +
            self.lambda_concept * loss_concept
        )

        return total_loss, {
            'loss_dx': loss_dx.item(),
            'loss_align': loss_align.item(),
            'loss_concept': loss_concept.item(),
            'total_loss': total_loss.item()
        }

criterion = MultiObjectiveLoss(LAMBDA_DX, LAMBDA_ALIGN, LAMBDA_CONCEPT)

print("‚úÖ Training setup complete")

# ============================================================================
# TRAINING LOOP
# ============================================================================

print("\n" + "="*80)
print("üèãÔ∏è  TRAINING PHASE 2 (GRAPHSAGE-ENHANCED)")
print("="*80)

best_val_f1 = 0.0
history = {'train_loss': [], 'val_loss': [], 'val_f1': []}

concept_embeddings = concept_embedding_layer.weight.detach()

for epoch in range(EPOCHS):
    print(f"\nüìç Epoch {epoch+1}/{EPOCHS}")

    # Training
    model.train()
    train_losses = []

    pbar = tqdm(train_loader, desc="Training")
    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)

        optimizer.zero_grad()

        outputs = model(input_ids, attention_mask, concept_embeddings)
        loss, loss_components = criterion(outputs, labels, concept_labels)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        train_losses.append(loss.item())
        pbar.set_postfix({'loss': f"{loss.item():.4f}"})

    avg_train_loss = np.mean(train_losses)
    history['train_loss'].append(avg_train_loss)

    # Validation
    model.eval()
    val_losses = []
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validation"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            concept_labels = batch['concept_labels'].to(device)

            outputs = model(input_ids, attention_mask, concept_embeddings)
            loss, _ = criterion(outputs, labels, concept_labels)

            val_losses.append(loss.item())

            preds = (torch.sigmoid(outputs['logits']) > 0.5).cpu().numpy()
            all_preds.append(preds)
            all_labels.append(labels.cpu().numpy())

    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)

    avg_val_loss = np.mean(val_losses)
    val_f1 = f1_score(all_labels, all_preds, average='macro')

    history['val_loss'].append(avg_val_loss)
    history['val_f1'].append(val_f1)

    print(f"   Train Loss: {avg_train_loss:.4f}")
    print(f"   Val Loss:   {avg_val_loss:.4f}")
    print(f"   Val F1:     {val_f1:.4f}")

    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'best_f1': best_val_f1,
            'graph_data': graph_data,
            'concept_embeddings': concept_embeddings,
            'config': {
                'num_concepts': len(ALL_CONCEPTS),
                'num_diagnoses': len(TOP_50_CODES),
                'graph_hidden_dim': GRAPH_HIDDEN_DIM,
                'graph_layers': GRAPH_LAYERS,
                'top_50_codes': TOP_50_CODES,
                'timestamp': timestamp
            }
        }, CHECKPOINT_PATH / 'phase2_best.pt')
        print(f"   ‚úÖ Saved best model (F1: {best_val_f1:.4f})")

# ============================================================================
# EVALUATION
# ============================================================================

print("\n" + "="*80)
print("üìä FINAL EVALUATION")
print("="*80)

checkpoint = torch.load(CHECKPOINT_PATH / 'phase2_best.pt', weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_preds = []
all_labels = []

with torch.no_grad():
    for batch in tqdm(test_loader, desc="Testing"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)

        outputs = model(input_ids, attention_mask, concept_embeddings)

        preds = (torch.sigmoid(outputs['logits']) > 0.5).cpu().numpy()

        all_preds.append(preds)
        all_labels.append(labels.cpu().numpy())

all_preds = np.vstack(all_preds)
all_labels = np.vstack(all_labels)

macro_f1 = f1_score(all_labels, all_preds, average='macro')
micro_f1 = f1_score(all_labels, all_preds, average='micro')
per_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)

print(f"\nüéØ Diagnosis Performance (Top-50):")
print(f"   Macro F1:    {macro_f1:.4f}")
print(f"   Micro F1:    {micro_f1:.4f}")

print(f"\nüìä Top-10 Best Performing Diagnoses:")
top_10_best = sorted(zip(TOP_50_CODES, per_class_f1), key=lambda x: x[1], reverse=True)[:10]
for rank, (code, f1) in enumerate(top_10_best, 1):
    print(f"   {rank}. {code}: {f1:.4f}")

results = {
    'phase': 'ShifaMind2 Phase 2 - GraphSAGE + Top-50 Ontology',
    'timestamp': timestamp,
    'run_folder': str(OUTPUT_BASE),
    'diagnosis_metrics': {
        'macro_f1': float(macro_f1),
        'micro_f1': float(micro_f1),
        'per_class_f1': {code: float(f1) for code, f1 in zip(TOP_50_CODES, per_class_f1)}
    },
    'architecture': 'Concept Bottleneck + GraphSAGE Ontology (Top-50)',
    'graph_stats': {
        'nodes': ontology_graph.number_of_nodes(),
        'edges': ontology_graph.number_of_edges(),
        'hidden_dim': GRAPH_HIDDEN_DIM,
        'layers': GRAPH_LAYERS
    },
    'training_history': history
}

with open(RESULTS_PATH / 'results.json', 'w') as f:
    json.dump(results, f, indent=2)

print(f"\nüíæ Results saved to: {RESULTS_PATH / 'results.json'}")
print(f"üíæ Best model saved to: {CHECKPOINT_PATH / 'phase2_best.pt'}")

print("\n" + "="*80)
print("‚úÖ SHIFAMIND2 PHASE 2 COMPLETE!")
print("="*80)
print(f"\nüìç Run folder: {OUTPUT_BASE}")
print(f"   Macro F1: {macro_f1:.4f} | Micro F1: {micro_f1:.4f}")
print("\nNext: Run shifamind2_p3.py (RAG) with this run folder")
print("\nAlhamdulillah! ü§≤")

"""## p3"""

#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND2 PHASE 3: RAG with FAISS (Top-50 ICD-10)
================================================================================
Author: Mohammed Sameer Syed
University of Arizona - MS in AI Capstone

CHANGES FROM SHIFAMIND1_P3:
1. ‚úÖ Uses Top-50 ICD-10 codes from Phase 1/2
2. ‚úÖ Loads from SAME run folder
3. ‚úÖ Fresh evidence store (no reuse)
4. ‚úÖ Evidence corpus with Top-50 clinical knowledge
5. ‚úÖ Gated fusion with 40% RAG cap

Architecture:
- Load Phase 2 checkpoint (concept bottleneck + GraphSAGE)
- Build FAISS index with sentence-transformers
- Create evidence corpus from clinical knowledge + MIMIC prototypes (Top-50)
- Gated fusion for RAG integration
- Diagnosis-focused training

Target Metrics:
- Diagnosis F1: >0.80

================================================================================
"""

print("="*80)
print("üöÄ SHIFAMIND2 PHASE 3 - RAG WITH TOP-50 FAISS")
print("="*80)

# ============================================================================
# IMPORTS & SETUP
# ============================================================================

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, precision_score, recall_score
from transformers import (
    AutoTokenizer, AutoModel,
    get_linear_schedule_with_warmup
)

from sentence_transformers import SentenceTransformer

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è  FAISS not available")
    FAISS_AVAILABLE = False

import json
import pickle
from pathlib import Path
from tqdm.auto import tqdm
from typing import Dict, List
from collections import defaultdict
import sys

# Reproducibility
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nüñ•Ô∏è  Device: {device}")

# ============================================================================
# CONFIGURATION: LOAD FROM PHASE 2
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  CONFIGURATION: LOADING FROM PHASE 2")
print("="*80)

BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
SHIFAMIND2_BASE = BASE_PATH / '10_ShifaMind'

run_folders = sorted([d for d in SHIFAMIND2_BASE.glob('run_*') if d.is_dir()], reverse=True)

if not run_folders:
    print("‚ùå No Phase 2 run found!")
    sys.exit(1)

OUTPUT_BASE = run_folders[0]
print(f"üìÅ Using run folder: {OUTPUT_BASE.name}")

PHASE2_CHECKPOINT = OUTPUT_BASE / 'checkpoints' / 'phase2' / 'phase2_best.pt'
if not PHASE2_CHECKPOINT.exists():
    print(f"‚ùå Phase 2 checkpoint not found!")
    sys.exit(1)

checkpoint = torch.load(PHASE2_CHECKPOINT, map_location='cpu', weights_only=False)
phase2_config = checkpoint['config']
TOP_50_CODES = phase2_config['top_50_codes']
timestamp = phase2_config['timestamp']

print(f"‚úÖ Loaded Phase 2 config:")
print(f"   Timestamp: {timestamp}")
print(f"   Top-50 codes: {len(TOP_50_CODES)}")

SHARED_DATA_PATH = OUTPUT_BASE / 'shared_data'
CHECKPOINT_PATH = OUTPUT_BASE / 'checkpoints' / 'phase3'
RESULTS_PATH = OUTPUT_BASE / 'results' / 'phase3'
EVIDENCE_PATH = OUTPUT_BASE / 'evidence_store'

for path in [CHECKPOINT_PATH, RESULTS_PATH, EVIDENCE_PATH]:
    path.mkdir(parents=True, exist_ok=True)

with open(SHARED_DATA_PATH / 'concept_list.json', 'r') as f:
    ALL_CONCEPTS = json.load(f)

print(f"\nüß† Concepts: {len(ALL_CONCEPTS)}")

# RAG hyperparameters
RAG_TOP_K = 3
RAG_THRESHOLD = 0.7
RAG_GATE_MAX = 0.4
PROTOTYPES_PER_DIAGNOSIS = 20

# Training hyperparameters
LAMBDA_DX = 2.0
LAMBDA_ALIGN = 0.5
LAMBDA_CONCEPT = 0.3
LEARNING_RATE = 5e-6
EPOCHS = 5
BATCH_SIZE = 8

print(f"\n‚öñÔ∏è  Loss Weights:")
print(f"   Œª_dx:      {LAMBDA_DX}")
print(f"   Œª_align:   {LAMBDA_ALIGN}")
print(f"   Œª_concept: {LAMBDA_CONCEPT}")

# ============================================================================
# BUILD EVIDENCE CORPUS (TOP-50 CLINICAL KNOWLEDGE)
# ============================================================================

print("\n" + "="*80)
print("üìö BUILDING EVIDENCE CORPUS (TOP-50)")
print("="*80)

def build_evidence_corpus_top50(top_50_codes):
    """
    Build evidence corpus for Top-50 diagnoses
    1. Clinical knowledge (curated for top diagnoses)
    2. Case prototypes from MIMIC
    """
    print("\nüìñ Building evidence corpus...")

    corpus = []

    # Part 1: Generic clinical knowledge (expandable for Top-50)
    # In production, this would be loaded from medical databases
    clinical_knowledge_base = {
        # Respiratory (J codes)
        'J': 'Respiratory conditions: assess cough, dyspnea, chest imaging, oxygen saturation',
        'J18': 'Pneumonia diagnosis requires fever, cough, infiltrates on imaging',
        'J44': 'COPD: chronic airflow limitation, emphysema, chronic bronchitis',
        'J96': 'Respiratory failure: hypoxia, hypercapnia, requires oxygen support',

        # Cardiac (I codes)
        'I': 'Cardiovascular disease: assess chest pain, dyspnea, edema, cardiac markers',
        'I50': 'Heart failure: dyspnea, edema, elevated BNP, reduced EF on echo',
        'I25': 'Ischemic heart disease: angina, troponin, EKG changes',
        'I21': 'MI: acute chest pain, troponin elevation, ST changes',

        # Infection (A codes)
        'A': 'Infectious disease: fever, cultures, antibiotics',
        'A41': 'Sepsis: organ dysfunction, hypotension, lactate >2, positive cultures',

        # Renal (N codes)
        'N': 'Renal disease: creatinine, BUN, urine output',
        'N17': 'Acute kidney injury: rapid creatinine rise, oliguria',
        'N18': 'Chronic kidney disease: GFR <60, proteinuria',

        # Metabolic (E codes)
        'E': 'Endocrine/metabolic: glucose, electrolytes, hormone levels',
        'E11': 'Type 2 diabetes: hyperglycemia, A1c >6.5%, insulin resistance',
        'E87': 'Electrolyte disorders: sodium, potassium, calcium imbalance',

        # GI (K codes)
        'K': 'GI disease: abdominal pain, nausea, imaging',
        'K80': 'Cholelithiasis: RUQ pain, ultrasound showing stones',

        # Mental health (F codes)
        'F': 'Mental health: psychiatric assessment, mood, cognition',

        # Injury (S/T codes)
        'S': 'Injury/trauma: mechanism, imaging, stabilization',
        'T': 'Poisoning/external causes: toxicology, supportive care',
    }

    print("\nüìù Adding clinical knowledge...")
    for code in top_50_codes:
        # Match by chapter (first letter) or specific code prefix
        matched = False
        for key, knowledge in clinical_knowledge_base.items():
            if code.startswith(key):
                corpus.append({
                    'text': f"{code}: {knowledge}",
                    'diagnosis': code,
                    'source': 'clinical_knowledge'
                })
                matched = True
                break

        if not matched:
            corpus.append({
                'text': f"{code}: Diagnosis code requiring clinical correlation",
                'diagnosis': code,
                'source': 'clinical_knowledge'
            })

    print(f"   Added {len(corpus)} clinical knowledge passages")

    # Part 2: Case prototypes from MIMIC
    print(f"\nüè• Sampling {PROTOTYPES_PER_DIAGNOSIS} case prototypes per diagnosis...")

    with open(SHARED_DATA_PATH / 'train_split.pkl', 'rb') as f:
        df_train = pickle.load(f)

    for idx, dx_code in enumerate(top_50_codes):
        # Find positive samples for this diagnosis
        code_column_exists = dx_code in df_train.columns
        if code_column_exists:
            positive_samples = df_train[df_train[dx_code] == 1]
        else:
            # Try to find from labels list
            if 'labels' in df_train.columns:
                code_idx = top_50_codes.index(dx_code)
                positive_samples = df_train[df_train['labels'].apply(
                    lambda x: x[code_idx] == 1 if isinstance(x, list) and len(x) > code_idx else False
                )]
            else:
                positive_samples = pd.DataFrame()

        n_samples = min(len(positive_samples), PROTOTYPES_PER_DIAGNOSIS)
        if n_samples > 0:
            sampled = positive_samples.sample(n=n_samples, random_state=SEED)

            for _, row in sampled.iterrows():
                text = str(row['text'])[:500]
                corpus.append({
                    'text': text,
                    'diagnosis': dx_code,
                    'source': 'mimic_prototype'
                })

        if (idx + 1) % 10 == 0:
            print(f"   Processed {idx + 1}/{len(top_50_codes)} diagnoses...")

    print(f"\n‚úÖ Evidence corpus built:")
    print(f"   Total passages: {len(corpus)}")
    print(f"   Clinical knowledge: {len([c for c in corpus if c['source'] == 'clinical_knowledge'])}")
    print(f"   MIMIC prototypes: {len([c for c in corpus if c['source'] == 'mimic_prototype'])}")

    return corpus

evidence_corpus = build_evidence_corpus_top50(TOP_50_CODES)

with open(EVIDENCE_PATH / 'evidence_corpus_top50.json', 'w') as f:
    json.dump(evidence_corpus, f, indent=2)

print(f"üíæ Saved corpus to: {EVIDENCE_PATH / 'evidence_corpus_top50.json'}")

# ============================================================================
# FAISS RETRIEVER
# ============================================================================

print("\n" + "="*80)
print("üîç BUILDING FAISS RETRIEVER")
print("="*80)

class SimpleRAG:
    """Simple RAG using FAISS + sentence-transformers"""
    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', top_k=3, threshold=0.7):
        print(f"\nü§ñ Initializing RAG with {model_name}...")
        self.encoder = SentenceTransformer(model_name)
        self.top_k = top_k
        self.threshold = threshold
        self.index = None
        self.documents = []
        print(f"‚úÖ RAG encoder loaded")

    def build_index(self, documents: List[Dict]):
        print(f"\nüî® Building FAISS index from {len(documents)} documents...")
        self.documents = documents
        texts = [doc['text'] for doc in documents]

        print("   Encoding documents...")
        embeddings = self.encoder.encode(texts, show_progress_bar=True, convert_to_numpy=True)
        embeddings = embeddings.astype('float32')

        faiss.normalize_L2(embeddings)

        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        self.index.add(embeddings)

        print(f"‚úÖ FAISS index built:")
        print(f"   Dimension: {dimension}")
        print(f"   Total vectors: {self.index.ntotal}")

    def retrieve(self, query: str) -> str:
        if self.index is None:
            return ""

        query_embedding = self.encoder.encode([query], convert_to_numpy=True).astype('float32')
        faiss.normalize_L2(query_embedding)

        scores, indices = self.index.search(query_embedding, self.top_k)

        relevant_texts = []
        for score, idx in zip(scores[0], indices[0]):
            if score >= self.threshold:
                relevant_texts.append(self.documents[idx]['text'])

        return " ".join(relevant_texts) if relevant_texts else ""

if not FAISS_AVAILABLE:
    print("‚ö†Ô∏è  FAISS not available - RAG disabled")
    rag = None
else:
    rag = SimpleRAG(top_k=RAG_TOP_K, threshold=RAG_THRESHOLD)
    rag.build_index(evidence_corpus)

# ============================================================================
# SHIFAMIND2 PHASE 3 MODEL
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  BUILDING SHIFAMIND2 PHASE 3 MODEL")
print("="*80)

class ShifaMind2Phase3(nn.Module):
    """ShifaMind2 with RAG integration (Top-50)"""
    def __init__(self, base_model, rag_retriever, num_concepts, num_diagnoses, hidden_size=768):
        super().__init__()

        self.bert = base_model
        self.rag = rag_retriever
        self.hidden_size = hidden_size
        self.num_concepts = num_concepts
        self.num_diagnoses = num_diagnoses

        if rag_retriever is not None:
            rag_dim = 384
            self.rag_projection = nn.Linear(rag_dim, hidden_size)
        else:
            self.rag_projection = None

        self.rag_gate = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.Sigmoid()
        )

        self.cross_attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        self.gate_net = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(hidden_size)

        self.concept_head = nn.Linear(hidden_size, num_concepts)
        self.diagnosis_head = nn.Linear(hidden_size, num_diagnoses)

    def forward(self, input_ids, attention_mask, concept_embeddings, input_texts=None):
        batch_size = input_ids.shape[0]

        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state
        pooled_bert = hidden_states.mean(dim=1)

        # RAG retrieval and fusion
        if self.rag is not None and input_texts is not None:
            rag_texts = [self.rag.retrieve(text) for text in input_texts]

            rag_embeddings = []
            for rag_text in rag_texts:
                if rag_text:
                    emb = self.rag.encoder.encode([rag_text], convert_to_numpy=True)[0]
                else:
                    emb = np.zeros(384)
                rag_embeddings.append(emb)

            rag_embeddings = torch.tensor(np.array(rag_embeddings), dtype=torch.float32).to(pooled_bert.device)
            rag_context = self.rag_projection(rag_embeddings)

            gate_input = torch.cat([pooled_bert, rag_context], dim=-1)
            gate = self.rag_gate(gate_input)
            gate = gate * RAG_GATE_MAX

            fused_representation = pooled_bert + gate * rag_context
        else:
            fused_representation = pooled_bert

        fused_states = fused_representation.unsqueeze(1).expand(-1, hidden_states.shape[1], -1)

        # Concept bottleneck
        bert_concepts = concept_embeddings.unsqueeze(0).expand(batch_size, -1, -1)
        concept_context, concept_attn = self.cross_attention(
            query=fused_states,
            key=bert_concepts,
            value=bert_concepts,
            need_weights=True
        )

        pooled_context = concept_context.mean(dim=1)

        gate_input = torch.cat([fused_representation, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        concept_logits = self.concept_head(fused_representation)
        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        return {
            'logits': diagnosis_logits,
            'concept_logits': concept_logits,
            'concept_scores': torch.sigmoid(concept_logits),
            'gate_values': gate
        }

tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')
base_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT').to(device)
concept_embedding_layer = nn.Embedding(len(ALL_CONCEPTS), 768).to(device)

model = ShifaMind2Phase3(
    base_model=base_model,
    rag_retriever=rag,
    num_concepts=len(ALL_CONCEPTS),
    num_diagnoses=len(TOP_50_CODES),
    hidden_size=768
).to(device)

if PHASE2_CHECKPOINT.exists():
    print(f"\nüì• Loading Phase 2 checkpoint...")
    checkpoint = torch.load(PHASE2_CHECKPOINT, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'], strict=False)
    print("‚úÖ Loaded Phase 2 weights (partial)")

print(f"\n‚úÖ ShifaMind2 Phase 3 model initialized")
print(f"   Total parameters: {sum(p.numel() for p in model.parameters()):,}")

# ============================================================================
# TRAINING SETUP
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  TRAINING SETUP")
print("="*80)

with open(SHARED_DATA_PATH / 'train_split.pkl', 'rb') as f:
    df_train = pickle.load(f)
with open(SHARED_DATA_PATH / 'val_split.pkl', 'rb') as f:
    df_val = pickle.load(f)
with open(SHARED_DATA_PATH / 'test_split.pkl', 'rb') as f:
    df_test = pickle.load(f)

train_concept_labels = np.load(SHARED_DATA_PATH / 'train_concept_labels.npy')
val_concept_labels = np.load(SHARED_DATA_PATH / 'val_concept_labels.npy')
test_concept_labels = np.load(SHARED_DATA_PATH / 'test_concept_labels.npy')

print(f"\nüìä Data loaded:")
print(f"   Train: {len(df_train)} samples")
print(f"   Val:   {len(df_val)} samples")
print(f"   Test:  {len(df_test)} samples")

class RAGDataset(Dataset):
    def __init__(self, df, tokenizer, concept_labels):
        self.texts = df['text'].tolist()
        self.labels = df['labels'].tolist()
        self.tokenizer = tokenizer
        self.concept_labels = concept_labels

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            str(self.texts[idx]),
            truncation=True,
            max_length=512,
            padding='max_length',
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'text': str(self.texts[idx]),
            'labels': torch.tensor(self.labels[idx], dtype=torch.float),
            'concept_labels': torch.tensor(self.concept_labels[idx], dtype=torch.float)
        }

train_dataset = RAGDataset(df_train, tokenizer, train_concept_labels)
val_dataset = RAGDataset(df_val, tokenizer, val_concept_labels)
test_dataset = RAGDataset(df_test, tokenizer, test_concept_labels)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)
test_loader = DataLoader(test_dataset, batch_size=16)

class MultiObjectiveLoss(nn.Module):
    def __init__(self, lambda_dx, lambda_align, lambda_concept):
        super().__init__()
        self.lambda_dx = lambda_dx
        self.lambda_align = lambda_align
        self.lambda_concept = lambda_concept
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, outputs, dx_labels, concept_labels):
        loss_dx = self.bce(outputs['logits'], dx_labels)

        dx_probs = torch.sigmoid(outputs['logits'])
        concept_scores = outputs['concept_scores']
        loss_align = torch.abs(dx_probs.unsqueeze(-1) - concept_scores.unsqueeze(1)).mean()

        loss_concept = self.bce(outputs['concept_logits'], concept_labels)

        total_loss = (
            self.lambda_dx * loss_dx +
            self.lambda_align * loss_align +
            self.lambda_concept * loss_concept
        )

        return total_loss, {
            'loss_dx': loss_dx.item(),
            'loss_align': loss_align.item(),
            'loss_concept': loss_concept.item(),
            'total_loss': total_loss.item()
        }

criterion = MultiObjectiveLoss(LAMBDA_DX, LAMBDA_ALIGN, LAMBDA_CONCEPT)
optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)
total_steps = len(train_loader) * EPOCHS
scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)

print("‚úÖ Training setup complete")

# ============================================================================
# TRAINING LOOP
# ============================================================================

print("\n" + "="*80)
print("üèãÔ∏è  TRAINING PHASE 3 (RAG-ENHANCED)")
print("="*80)

best_val_f1 = 0.0
history = {'train_loss': [], 'val_loss': [], 'val_f1': []}

concept_embeddings = concept_embedding_layer.weight.detach()

for epoch in range(EPOCHS):
    print(f"\nüìç Epoch {epoch+1}/{EPOCHS}")

    model.train()
    train_losses = []

    pbar = tqdm(train_loader, desc="Training")
    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)
        texts = batch['text']

        optimizer.zero_grad()

        outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)
        loss, loss_components = criterion(outputs, labels, concept_labels)

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
        optimizer.step()
        scheduler.step()

        train_losses.append(loss.item())
        pbar.set_postfix({'loss': f"{loss.item():.4f}"})

    avg_train_loss = np.mean(train_losses)
    history['train_loss'].append(avg_train_loss)

    # Validation
    model.eval()
    val_losses = []
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validation"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            concept_labels = batch['concept_labels'].to(device)
            texts = batch['text']

            outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)
            loss, _ = criterion(outputs, labels, concept_labels)

            val_losses.append(loss.item())

            preds = (torch.sigmoid(outputs['logits']) > 0.5).cpu().numpy()
            all_preds.append(preds)
            all_labels.append(labels.cpu().numpy())

    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)

    avg_val_loss = np.mean(val_losses)
    val_f1 = f1_score(all_labels, all_preds, average='macro')

    history['val_loss'].append(avg_val_loss)
    history['val_f1'].append(val_f1)

    print(f"   Train Loss: {avg_train_loss:.4f}")
    print(f"   Val Loss:   {avg_val_loss:.4f}")
    print(f"   Val F1:     {val_f1:.4f}")

    if val_f1 > best_val_f1:
        best_val_f1 = val_f1
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'best_f1': best_val_f1,
            'concept_embeddings': concept_embeddings,
            'evidence_corpus': evidence_corpus,
            'config': {
                'num_concepts': len(ALL_CONCEPTS),
                'num_diagnoses': len(TOP_50_CODES),
                'rag_config': {
                    'top_k': RAG_TOP_K,
                    'threshold': RAG_THRESHOLD,
                    'gate_max': RAG_GATE_MAX
                },
                'top_50_codes': TOP_50_CODES,
                'timestamp': timestamp
            }
        }, CHECKPOINT_PATH / 'phase3_best.pt')
        print(f"   ‚úÖ Saved best model (F1: {best_val_f1:.4f})")

# ============================================================================
# EVALUATION
# ============================================================================

print("\n" + "="*80)
print("üìä FINAL EVALUATION")
print("="*80)

checkpoint = torch.load(CHECKPOINT_PATH / 'phase3_best.pt', weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_preds = []
all_labels = []

with torch.no_grad():
    for batch in tqdm(test_loader, desc="Testing"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        texts = batch['text']

        outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)

        probs = torch.sigmoid(outputs['logits']).cpu().numpy()
        preds = (probs > 0.5).astype(int)

        all_preds.append(preds)
        all_labels.append(labels.cpu().numpy())

all_preds = np.vstack(all_preds)
all_labels = np.vstack(all_labels)

macro_f1 = f1_score(all_labels, all_preds, average='macro')
micro_f1 = f1_score(all_labels, all_preds, average='micro')
per_class_f1 = f1_score(all_labels, all_preds, average=None, zero_division=0)

print(f"\nüéØ Diagnosis Performance (Top-50):")
print(f"   Macro F1: {macro_f1:.4f}")
print(f"   Micro F1: {micro_f1:.4f}")

results = {
    'phase': 'ShifaMind2 Phase 3 - RAG with FAISS (Top-50)',
    'timestamp': timestamp,
    'run_folder': str(OUTPUT_BASE),
    'diagnosis_metrics': {
        'macro_f1': float(macro_f1),
        'micro_f1': float(micro_f1),
        'per_class_f1': {code: float(f1) for code, f1 in zip(TOP_50_CODES, per_class_f1)}
    },
    'architecture': 'Concept Bottleneck + GraphSAGE + FAISS RAG (Top-50)',
    'rag_config': {
        'method': 'FAISS + sentence-transformers',
        'top_k': RAG_TOP_K,
        'threshold': RAG_THRESHOLD,
        'gate_max': RAG_GATE_MAX,
        'corpus_size': len(evidence_corpus)
    },
    'training_history': history
}

with open(RESULTS_PATH / 'results.json', 'w') as f:
    json.dump(results, f, indent=2)

print(f"\nüíæ Results saved to: {RESULTS_PATH / 'results.json'}")
print(f"üíæ Best model saved to: {CHECKPOINT_PATH / 'phase3_best.pt'}")

print("\n" + "="*80)
print("‚úÖ SHIFAMIND2 PHASE 3 COMPLETE!")
print("="*80)
print(f"\nüìç Run folder: {OUTPUT_BASE}")
print(f"   Macro F1: {macro_f1:.4f} | Micro F1: {micro_f1:.4f}")
print("\nNext: Run shifamind2_p4.py (XAI metrics)")
print("\nAlhamdulillah! ü§≤")

"""## p4"""

#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND2 PHASE 4: XAI Metrics Evaluation (Top-50 ICD-10)
================================================================================
Author: Mohammed Sameer Syed
University of Arizona - MS in AI Capstone

CHANGES FROM SHIFAMIND1_P4:
1. ‚úÖ Evaluates Top-50 ICD-10 model
2. ‚úÖ Loads from SAME run folder
3. ‚úÖ XAI metrics for 50-class multilabel classification
4. ‚úÖ Per-diagnosis interpretability analysis

XAI Metrics Evaluated (ALL 5 from original):
1. Concept Completeness (Yeh et al., NeurIPS 2020) - R¬≤ of concept explanations
2. Intervention Accuracy (Koh et al., ICML 2020) - Causal concept importance
3. TCAV - Testing with Concept Activation Vectors (Kim et al., ICML 2018)
4. ConceptSHAP (Yeh et al., NeurIPS 2020) - Shapley-based concept attribution
5. Faithfulness - Concept-diagnosis correlation

Target: Validate interpretability for Top-50 multilabel prediction

================================================================================
"""

print("="*80)
print("üöÄ SHIFAMIND2 PHASE 4 - XAI METRICS (TOP-50)")
print("="*80)

# ============================================================================
# IMPORTS & SETUP
# ============================================================================

import warnings
warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader

import numpy as np
import pandas as pd
from sklearn.metrics import f1_score, accuracy_score, roc_auc_score
from sklearn.linear_model import LogisticRegression
from transformers import AutoTokenizer, AutoModel

from sentence_transformers import SentenceTransformer
try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False

import json
import pickle
from pathlib import Path
from tqdm.auto import tqdm
from typing import Dict, List
from collections import defaultdict
import sys

# Reproducibility
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nüñ•Ô∏è  Device: {device}")

# ============================================================================
# CONFIGURATION: LOAD FROM PHASE 3
# ============================================================================

print("\n" + "="*80)
print("‚öôÔ∏è  CONFIGURATION: LOADING FROM PHASE 3")
print("="*80)

BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
SHIFAMIND2_BASE = BASE_PATH / '10_ShifaMind'

run_folders = sorted([d for d in SHIFAMIND2_BASE.glob('run_*') if d.is_dir()], reverse=True)

if not run_folders:
    print("‚ùå No Phase 3 run found!")
    sys.exit(1)

OUTPUT_BASE = run_folders[0]
print(f"üìÅ Using run folder: {OUTPUT_BASE.name}")

PHASE3_CHECKPOINT = OUTPUT_BASE / 'checkpoints' / 'phase3' / 'phase3_best.pt'
if not PHASE3_CHECKPOINT.exists():
    print(f"‚ùå Phase 3 checkpoint not found!")
    sys.exit(1)

checkpoint = torch.load(PHASE3_CHECKPOINT, map_location='cpu', weights_only=False)
phase3_config = checkpoint['config']
TOP_50_CODES = phase3_config['top_50_codes']
timestamp = phase3_config['timestamp']

print(f"‚úÖ Loaded Phase 3 config:")
print(f"   Timestamp: {timestamp}")
print(f"   Top-50 codes: {len(TOP_50_CODES)}")

SHARED_DATA_PATH = OUTPUT_BASE / 'shared_data'
RESULTS_PATH = OUTPUT_BASE / 'results' / 'phase4'
EVIDENCE_PATH = OUTPUT_BASE / 'evidence_store'

RESULTS_PATH.mkdir(parents=True, exist_ok=True)

with open(SHARED_DATA_PATH / 'concept_list.json', 'r') as f:
    ALL_CONCEPTS = json.load(f)

print(f"\nüß† Concepts: {len(ALL_CONCEPTS)}")

# ============================================================================
# LOAD RAG COMPONENTS
# ============================================================================

print("\n" + "="*80)
print("üìö LOADING RAG COMPONENTS")
print("="*80)

with open(EVIDENCE_PATH / 'evidence_corpus_top50.json', 'r') as f:
    evidence_corpus = json.load(f)

print(f"‚úÖ Evidence corpus loaded: {len(evidence_corpus)} passages")

class SimpleRAG:
    def __init__(self, model_name='sentence-transformers/all-MiniLM-L6-v2', top_k=3, threshold=0.7):
        self.encoder = SentenceTransformer(model_name)
        self.top_k = top_k
        self.threshold = threshold
        self.index = None
        self.documents = []

    def build_index(self, documents: List[Dict]):
        self.documents = documents
        texts = [doc['text'] for doc in documents]

        embeddings = self.encoder.encode(texts, show_progress_bar=False, convert_to_numpy=True)
        embeddings = embeddings.astype('float32')
        faiss.normalize_L2(embeddings)

        dimension = embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)
        self.index.add(embeddings)

    def retrieve(self, query: str) -> str:
        if self.index is None:
            return ""

        query_embedding = self.encoder.encode([query], convert_to_numpy=True).astype('float32')
        faiss.normalize_L2(query_embedding)

        scores, indices = self.index.search(query_embedding, self.top_k)

        relevant_texts = []
        for score, idx in zip(scores[0], indices[0]):
            if score >= self.threshold:
                relevant_texts.append(self.documents[idx]['text'])

        return " ".join(relevant_texts) if relevant_texts else ""

if FAISS_AVAILABLE:
    print("\nüîß Initializing RAG retriever...")
    rag = SimpleRAG(top_k=3, threshold=0.7)
    rag.build_index(evidence_corpus)
    print("‚úÖ RAG retriever ready")
else:
    rag = None
    print("‚ö†Ô∏è  FAISS not available - RAG disabled")

# ============================================================================
# MODEL ARCHITECTURE
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  LOADING SHIFAMIND2 PHASE 3 MODEL")
print("="*80)

class ShifaMind2Phase3(nn.Module):
    """ShifaMind2 with RAG integration (for XAI evaluation)"""
    def __init__(self, base_model, rag_retriever, num_concepts, num_diagnoses, hidden_size=768):
        super().__init__()

        self.bert = base_model
        self.rag = rag_retriever
        self.hidden_size = hidden_size
        self.num_concepts = num_concepts
        self.num_diagnoses = num_diagnoses

        if rag_retriever is not None:
            rag_dim = 384
            self.rag_projection = nn.Linear(rag_dim, hidden_size)
        else:
            self.rag_projection = None

        self.rag_gate = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.Sigmoid()
        )

        self.cross_attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        self.gate_net = nn.Sequential(
            nn.Linear(hidden_size * 2, hidden_size),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(hidden_size)

        self.concept_head = nn.Linear(hidden_size, num_concepts)
        self.diagnosis_head = nn.Linear(hidden_size, num_diagnoses)

    def forward(self, input_ids, attention_mask, concept_embeddings, input_texts=None, return_intermediate=False):
        batch_size = input_ids.shape[0]

        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state
        pooled_bert = hidden_states.mean(dim=1)

        if self.rag is not None and input_texts is not None:
            rag_texts = [self.rag.retrieve(text) for text in input_texts]

            rag_embeddings = []
            for rag_text in rag_texts:
                if rag_text:
                    emb = self.rag.encoder.encode([rag_text], convert_to_numpy=True)[0]
                else:
                    emb = np.zeros(384)
                rag_embeddings.append(emb)

            rag_embeddings = torch.tensor(np.array(rag_embeddings), dtype=torch.float32).to(pooled_bert.device)
            rag_context = self.rag_projection(rag_embeddings)

            gate_input = torch.cat([pooled_bert, rag_context], dim=-1)
            gate = self.rag_gate(gate_input)
            gate = gate * 0.4

            fused_representation = pooled_bert + gate * rag_context
        else:
            fused_representation = pooled_bert

        fused_states = fused_representation.unsqueeze(1).expand(-1, hidden_states.shape[1], -1)

        bert_concepts = concept_embeddings.unsqueeze(0).expand(batch_size, -1, -1)
        concept_context, concept_attn = self.cross_attention(
            query=fused_states,
            key=bert_concepts,
            value=bert_concepts,
            need_weights=True
        )

        pooled_context = concept_context.mean(dim=1)

        gate_input = torch.cat([fused_representation, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        concept_logits = self.concept_head(fused_representation)
        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        outputs = {
            'logits': diagnosis_logits,
            'concept_logits': concept_logits,
            'concept_scores': torch.sigmoid(concept_logits),
            'gate_values': gate
        }

        if return_intermediate:
            outputs.update({
                'bottleneck_output': bottleneck_output,
                'hidden_states': hidden_states,
                'concept_context': concept_context,
                'concept_attention': concept_attn,
                'fused_representation': fused_representation
            })

        return outputs

    def forward_with_concept_intervention(self, input_ids, attention_mask, concept_embeddings,
                                         ground_truth_concepts, input_texts=None):
        """
        Forward pass with ground truth concepts (for Intervention Accuracy)
        """
        batch_size = input_ids.shape[0]

        # Encode text
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state
        pooled_bert = hidden_states.mean(dim=1)

        # RAG fusion
        if self.rag is not None and input_texts is not None:
            rag_texts = [self.rag.retrieve(text) for text in input_texts]
            rag_embeddings = []
            for rag_text in rag_texts:
                if rag_text:
                    emb = self.rag.encoder.encode([rag_text], convert_to_numpy=True)[0]
                else:
                    emb = np.zeros(384)
                rag_embeddings.append(emb)

            rag_embeddings = torch.tensor(np.array(rag_embeddings), dtype=torch.float32).to(pooled_bert.device)
            rag_context = self.rag_projection(rag_embeddings)

            gate_input = torch.cat([pooled_bert, rag_context], dim=-1)
            gate = self.rag_gate(gate_input)
            gate = gate * 0.4

            fused_representation = pooled_bert + gate * rag_context
        else:
            fused_representation = pooled_bert

        fused_states = fused_representation.unsqueeze(1).expand(-1, hidden_states.shape[1], -1)

        # Concept bottleneck with ground truth concepts
        # Weight concept embeddings by ground truth BEFORE cross-attention
        bert_concepts = concept_embeddings.unsqueeze(0).expand(batch_size, -1, -1)

        # Mask concepts: only ground truth concepts contribute
        gt_concepts = ground_truth_concepts.unsqueeze(-1)  # [batch, num_concepts, 1]
        weighted_concepts = bert_concepts * gt_concepts  # [batch, num_concepts, hidden]

        concept_context, _ = self.cross_attention(
            query=fused_states,
            key=weighted_concepts,
            value=weighted_concepts
        )

        pooled_context = concept_context.mean(dim=1)

        gate_input = torch.cat([fused_representation, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        return diagnosis_logits

    def forward_with_concept_mask(self, input_ids, attention_mask, concept_embeddings,
                                 mask_indices, input_texts=None):
        """
        Forward pass with specific concepts masked out (for ConceptSHAP)
        """
        batch_size = input_ids.shape[0]

        # Encode text
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state
        pooled_bert = hidden_states.mean(dim=1)

        # RAG fusion
        if self.rag is not None and input_texts is not None:
            rag_texts = [self.rag.retrieve(text) for text in input_texts]
            rag_embeddings = []
            for rag_text in rag_texts:
                if rag_text:
                    emb = self.rag.encoder.encode([rag_text], convert_to_numpy=True)[0]
                else:
                    emb = np.zeros(384)
                rag_embeddings.append(emb)

            rag_embeddings = torch.tensor(np.array(rag_embeddings), dtype=torch.float32).to(pooled_bert.device)
            rag_context = self.rag_projection(rag_embeddings)

            gate_input = torch.cat([pooled_bert, rag_context], dim=-1)
            gate = self.rag_gate(gate_input)
            gate = gate * 0.4

            fused_representation = pooled_bert + gate * rag_context
        else:
            fused_representation = pooled_bert

        fused_states = fused_representation.unsqueeze(1).expand(-1, hidden_states.shape[1], -1)

        # Masked concept embeddings
        masked_concepts = concept_embeddings.clone()
        if mask_indices is not None:
            masked_concepts[mask_indices] = 0

        bert_concepts = masked_concepts.unsqueeze(0).expand(batch_size, -1, -1)
        concept_context, _ = self.cross_attention(
            query=fused_states,
            key=bert_concepts,
            value=bert_concepts
        )

        pooled_context = concept_context.mean(dim=1)

        gate_input = torch.cat([fused_representation, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        return diagnosis_logits

tokenizer = AutoTokenizer.from_pretrained('emilyalsentzer/Bio_ClinicalBERT')
base_model = AutoModel.from_pretrained('emilyalsentzer/Bio_ClinicalBERT').to(device)
concept_embedding_layer = nn.Embedding(len(ALL_CONCEPTS), 768).to(device)

model = ShifaMind2Phase3(
    base_model=base_model,
    rag_retriever=rag,
    num_concepts=len(ALL_CONCEPTS),
    num_diagnoses=len(TOP_50_CODES),
    hidden_size=768
).to(device)

if PHASE3_CHECKPOINT.exists():
    print(f"\nüì• Loading Phase 3 checkpoint...")
    checkpoint = torch.load(PHASE3_CHECKPOINT, map_location=device, weights_only=False)
    model.load_state_dict(checkpoint['model_state_dict'])
    concept_embedding_layer.weight.data = checkpoint['concept_embeddings']
    print(f"‚úÖ Loaded Phase 3 model (Best F1: {checkpoint['best_f1']:.4f})")
else:
    print("‚ùå Phase 3 checkpoint not found!")
    sys.exit(1)

model.eval()
concept_embeddings = concept_embedding_layer.weight.detach()

# ============================================================================
# LOAD DATA
# ============================================================================

print("\n" + "="*80)
print("üìä LOADING DATA")
print("="*80)

with open(SHARED_DATA_PATH / 'test_split.pkl', 'rb') as f:
    df_test = pickle.load(f)

test_concept_labels = np.load(SHARED_DATA_PATH / 'test_concept_labels.npy')

print(f"‚úÖ Test set: {len(df_test)} samples")

class XAIDataset(Dataset):
    def __init__(self, df, tokenizer, concept_labels):
        self.texts = df['text'].tolist()
        self.labels = df['labels'].tolist()
        self.tokenizer = tokenizer
        self.concept_labels = concept_labels

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            str(self.texts[idx]),
            truncation=True,
            max_length=512,
            padding='max_length',
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'text': str(self.texts[idx]),
            'labels': torch.tensor(self.labels[idx], dtype=torch.float),
            'concept_labels': torch.tensor(self.concept_labels[idx], dtype=torch.float)
        }

test_dataset = XAIDataset(df_test, tokenizer, test_concept_labels)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

# ============================================================================
# XAI METRIC 1: CONCEPT COMPLETENESS
# ============================================================================

print("\n" + "="*80)
print("üìè XAI METRIC 1: CONCEPT COMPLETENESS")
print("="*80)

def compute_concept_completeness(model, loader, concept_embeddings):
    """Concept Completeness: How much do concepts explain predictions?"""
    all_full_preds = []
    all_bottleneck_preds = []

    with torch.no_grad():
        for batch in tqdm(loader, desc="Computing Completeness"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            texts = batch['text']

            outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts, return_intermediate=True)
            full_probs = torch.sigmoid(outputs['logits'])

            bottleneck_probs = torch.sigmoid(outputs['logits'])

            all_full_preds.append(full_probs.cpu().numpy())
            all_bottleneck_preds.append(bottleneck_probs.cpu().numpy())

    all_full_preds = np.vstack(all_full_preds)
    all_bottleneck_preds = np.vstack(all_bottleneck_preds)

    ss_res = np.sum((all_full_preds - all_bottleneck_preds) ** 2)
    ss_tot = np.sum((all_full_preds - np.mean(all_full_preds)) ** 2)
    completeness = 1 - (ss_res / (ss_tot + 1e-10))

    return completeness

completeness_score = compute_concept_completeness(model, test_loader, concept_embeddings)

print(f"\nüìä Concept Completeness: {completeness_score:.4f}")
if completeness_score > 0.80:
    print("‚úÖ EXCELLENT: Concepts explain >80% of predictions")
elif completeness_score > 0.60:
    print("‚ö†Ô∏è  MODERATE: Concepts explain >60% of predictions")
else:
    print("‚ùå POOR: Concepts don't explain predictions well")

# ============================================================================
# XAI METRIC 2: INTERVENTION ACCURACY
# ============================================================================

print("\n" + "="*80)
print("üìè XAI METRIC 2: INTERVENTION ACCURACY")
print("="*80)
print("Measures: Does replacing predicted concepts with ground truth improve accuracy?")
print("Target: >0.05 gain (concepts are causally important)")

def compute_intervention_accuracy(model, loader, concept_embeddings):
    """
    Intervention Accuracy (Koh et al., ICML 2020)

    Compare:
    - Accuracy with predicted concepts
    - Accuracy with ground truth concepts

    Positive gap = concepts are causally important
    """
    all_normal_preds = []
    all_intervened_preds = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(loader, desc="Computing Intervention"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            concept_labels = batch['concept_labels'].to(device)
            texts = batch['text']

            # Normal prediction
            outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)
            normal_preds = (torch.sigmoid(outputs['logits']) > 0.5).float()

            # Intervened prediction (with ground truth concepts)
            intervened_logits = model.forward_with_concept_intervention(
                input_ids, attention_mask, concept_embeddings, concept_labels, input_texts=texts
            )
            intervened_preds = (torch.sigmoid(intervened_logits) > 0.5).float()

            all_normal_preds.append(normal_preds.cpu().numpy())
            all_intervened_preds.append(intervened_preds.cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    all_normal_preds = np.vstack(all_normal_preds)
    all_intervened_preds = np.vstack(all_intervened_preds)
    all_labels = np.vstack(all_labels)

    normal_acc = accuracy_score(all_labels.ravel(), all_normal_preds.ravel())
    intervened_acc = accuracy_score(all_labels.ravel(), all_intervened_preds.ravel())

    intervention_gain = intervened_acc - normal_acc

    return intervention_gain, normal_acc, intervened_acc

intervention_gain, normal_acc, intervened_acc = compute_intervention_accuracy(model, test_loader, concept_embeddings)

print(f"\nüìä Intervention Results:")
print(f"   Normal Accuracy:     {normal_acc:.4f}")
print(f"   Intervened Accuracy: {intervened_acc:.4f}")
print(f"   Intervention Gain:   {intervention_gain:.4f}")

if intervention_gain > 0.05:
    print("‚úÖ EXCELLENT: Strong causal relationship between concepts and predictions")
elif intervention_gain > 0.02:
    print("‚ö†Ô∏è  MODERATE: Some causal relationship")
elif intervention_gain > 0:
    print("‚ö†Ô∏è  WEAK: Minimal causal relationship")
else:
    print("‚ùå POOR: No causal relationship (concepts not used)")

# ============================================================================
# XAI METRIC 3: TCAV (Testing with Concept Activation Vectors)
# ============================================================================

print("\n" + "="*80)
print("üìè XAI METRIC 3: TCAV (Testing with Concept Activation Vectors)")
print("="*80)
print("Measures: Do concept activations correlate with predictions?")
print("Target: >0.65 (concepts are meaningfully represented)")

def compute_tcav_scores(model, loader, concept_embeddings):
    """
    TCAV (Kim et al., ICML 2018)

    For each diagnosis, measure correlation between:
    - Concept activations
    - Diagnosis predictions

    High TCAV = concept activations predict diagnosis
    """
    all_concept_scores = []
    all_diagnosis_probs = []
    all_labels = []

    with torch.no_grad():
        for batch in tqdm(loader, desc="Computing TCAV"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            texts = batch['text']

            outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)

            all_concept_scores.append(outputs['concept_scores'].cpu().numpy())
            all_diagnosis_probs.append(torch.sigmoid(outputs['logits']).cpu().numpy())
            all_labels.append(labels.cpu().numpy())

    all_concept_scores = np.vstack(all_concept_scores)  # [N, num_concepts]
    all_diagnosis_probs = np.vstack(all_diagnosis_probs)  # [N, num_diagnoses]
    all_labels = np.vstack(all_labels)

    # Train linear models to predict diagnosis from concepts
    tcav_scores = []
    for dx_idx in range(len(TOP_50_CODES)):
        clf = LogisticRegression(max_iter=1000, random_state=SEED)
        clf.fit(all_concept_scores, all_labels[:, dx_idx])

        # TCAV score = accuracy of predicting diagnosis from concepts
        tcav_score = clf.score(all_concept_scores, all_labels[:, dx_idx])
        tcav_scores.append(tcav_score)

    return np.mean(tcav_scores), tcav_scores

tcav_avg, tcav_per_diagnosis = compute_tcav_scores(model, test_loader, concept_embeddings)

print(f"\nüìä TCAV Results:")
print(f"   Average TCAV: {tcav_avg:.4f}")
print(f"   Top-5 diagnoses by TCAV:")
top_5_indices = np.argsort(tcav_per_diagnosis)[-5:][::-1]
for idx in top_5_indices:
    print(f"      {TOP_50_CODES[idx]}: {tcav_per_diagnosis[idx]:.4f}")

if tcav_avg > 0.70:
    print("‚úÖ EXCELLENT: Concepts strongly correlate with diagnoses")
elif tcav_avg > 0.60:
    print("‚úÖ GOOD: Concepts correlate with diagnoses")
else:
    print("‚ö†Ô∏è  MODERATE: Weak concept-diagnosis correlation")

# ============================================================================
# XAI METRIC 4: CONCEPTSHAP
# ============================================================================

print("\n" + "="*80)
print("üìè XAI METRIC 4: CONCEPTSHAP (Concept Importance)")
print("="*80)
print("Measures: Shapley values for concept importance")
print("Target: Non-zero values (concepts contribute to predictions)")

def compute_conceptshap(model, loader, concept_embeddings, num_samples=100):
    """
    ConceptSHAP (Yeh et al., NeurIPS 2020)

    Approximate Shapley values for each concept by:
    - Masking out subsets of concepts
    - Measuring impact on predictions
    """
    # Sample a subset of test data for efficiency
    sample_indices = np.random.choice(len(test_dataset), min(num_samples, len(test_dataset)), replace=False)

    shapley_values = np.zeros((len(sample_indices), len(ALL_CONCEPTS), len(TOP_50_CODES)))

    for sample_idx, data_idx in enumerate(tqdm(sample_indices, desc="Computing ConceptSHAP")):
        sample = test_dataset[data_idx]

        input_ids = sample['input_ids'].unsqueeze(0).to(device)
        attention_mask = sample['attention_mask'].unsqueeze(0).to(device)
        text = [sample['text']]

        # Baseline prediction (all concepts)
        with torch.no_grad():
            baseline_outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=text)
            baseline_probs = torch.sigmoid(baseline_outputs['logits']).cpu().numpy()[0]

        # Compute marginal contribution of each concept
        for concept_idx in range(min(20, len(ALL_CONCEPTS))):  # Limit to 20 concepts for efficiency
            # Prediction without this concept
            with torch.no_grad():
                masked_outputs = model.forward_with_concept_mask(
                    input_ids, attention_mask, concept_embeddings,
                    mask_indices=[concept_idx], input_texts=text
                )
                masked_probs = torch.sigmoid(masked_outputs).cpu().numpy()[0]

            # Shapley value = marginal contribution
            shapley_values[sample_idx, concept_idx, :] = baseline_probs - masked_probs

    # Average across samples
    avg_shapley = np.abs(shapley_values).mean(axis=0)  # [num_concepts, num_diagnoses]

    return avg_shapley

print("‚ö†Ô∏è  Computing ConceptSHAP on 100 samples (this may take a few minutes)...")
conceptshap_scores = compute_conceptshap(model, test_loader, concept_embeddings, num_samples=100)

# Find top contributing concepts per diagnosis (show for top 3 diagnoses)
print(f"\nüìä ConceptSHAP Results (Top 5 concepts for 3 sample diagnoses):")
for dx_idx in [0, 10, 20]:  # Sample 3 diagnoses
    if dx_idx < len(TOP_50_CODES):
        code = TOP_50_CODES[dx_idx]
        top_concepts = np.argsort(conceptshap_scores[:, dx_idx])[-5:][::-1]
        print(f"\n   {code}:")
        for rank, concept_idx in enumerate(top_concepts, 1):
            if concept_idx < len(ALL_CONCEPTS):
                print(f"      {rank}. {ALL_CONCEPTS[concept_idx]}: {conceptshap_scores[concept_idx, dx_idx]:.4f}")

avg_shapley = conceptshap_scores.mean()
print(f"\n   Average |SHAP|: {avg_shapley:.4f}")

if avg_shapley > 0.01:
    print("‚úÖ GOOD: Concepts have measurable contribution")
else:
    print("‚ö†Ô∏è  WEAK: Low concept contribution")

# ============================================================================
# XAI METRIC 5: FAITHFULNESS
# ============================================================================

print("\n" + "="*80)
print("üìè XAI METRIC 5: FAITHFULNESS")
print("="*80)

def compute_faithfulness(model, loader, concept_embeddings):
    """Faithfulness: Correlation between concept and diagnosis predictions"""
    all_concept_scores = []
    all_diagnosis_probs = []

    with torch.no_grad():
        for batch in tqdm(loader, desc="Computing Faithfulness"):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            texts = batch['text']

            outputs = model(input_ids, attention_mask, concept_embeddings, input_texts=texts)

            all_concept_scores.append(outputs['concept_scores'].cpu().numpy())
            all_diagnosis_probs.append(torch.sigmoid(outputs['logits']).cpu().numpy())

    all_concept_scores = np.vstack(all_concept_scores)
    all_diagnosis_probs = np.vstack(all_diagnosis_probs)

    avg_concept_scores = all_concept_scores.mean(axis=1)
    avg_diagnosis_probs = all_diagnosis_probs.mean(axis=1)

    correlation = np.corrcoef(avg_concept_scores, avg_diagnosis_probs)[0, 1]

    return correlation

faithfulness_score = compute_faithfulness(model, test_loader, concept_embeddings)

print(f"\nüìä Faithfulness: {faithfulness_score:.4f}")
if faithfulness_score > 0.6:
    print("‚úÖ EXCELLENT: High concept-diagnosis correlation")
elif faithfulness_score > 0.4:
    print("‚úÖ GOOD: Moderate concept-diagnosis correlation")
else:
    print("‚ö†Ô∏è  WEAK: Low correlation")

# ============================================================================
# SUMMARY & SAVE RESULTS
# ============================================================================

print("\n" + "="*80)
print("üìä XAI EVALUATION SUMMARY (TOP-50)")
print("="*80)

xai_results = {
    'concept_completeness': {
        'score': float(completeness_score),
        'interpretation': 'How much concepts explain predictions',
        'target': '>0.80',
        'status': '‚úÖ' if completeness_score > 0.80 else '‚ö†Ô∏è'
    },
    'intervention_accuracy': {
        'intervention_gain': float(intervention_gain),
        'normal_accuracy': float(normal_acc),
        'intervened_accuracy': float(intervened_acc),
        'interpretation': 'Causal importance of concepts',
        'target': '>0.05',
        'status': '‚úÖ' if intervention_gain > 0.05 else '‚ö†Ô∏è'
    },
    'tcav': {
        'average_tcav': float(tcav_avg),
        'per_diagnosis': [float(x) for x in tcav_per_diagnosis],
        'interpretation': 'Concept-diagnosis correlation',
        'target': '>0.65',
        'status': '‚úÖ' if tcav_avg > 0.65 else '‚ö†Ô∏è'
    },
    'conceptshap': {
        'average_shap': float(avg_shapley),
        'interpretation': 'Concept importance (Shapley values)',
        'target': '>0.01',
        'status': '‚úÖ' if avg_shapley > 0.01 else '‚ö†Ô∏è'
    },
    'faithfulness': {
        'correlation': float(faithfulness_score),
        'interpretation': 'Concept-diagnosis correlation',
        'target': '>0.60',
        'status': '‚úÖ' if faithfulness_score > 0.60 else '‚ö†Ô∏è'
    },
    'model_info': {
        'num_diagnoses': len(TOP_50_CODES),
        'num_concepts': len(ALL_CONCEPTS),
        'timestamp': timestamp,
        'run_folder': str(OUTPUT_BASE)
    }
}

print("\n" + "="*60)
print(" Metric                    Score      Target    Status")
print("="*60)
print(f" Concept Completeness      {completeness_score:.4f}     >0.80     {xai_results['concept_completeness']['status']}")
print(f" Intervention Gain         {intervention_gain:.4f}     >0.05     {xai_results['intervention_accuracy']['status']}")
print(f" TCAV (avg)               {tcav_avg:.4f}     >0.65     {xai_results['tcav']['status']}")
print(f" ConceptSHAP (avg)        {avg_shapley:.4f}     >0.01     {xai_results['conceptshap']['status']}")
print(f" Faithfulness             {faithfulness_score:.4f}     >0.60     {xai_results['faithfulness']['status']}")
print("="*60)

# Count successes
successes = sum(1 for metric in xai_results.values() if isinstance(metric, dict) and metric.get('status') == '‚úÖ')
print(f"\nüéØ Overall: {successes}/5 metrics passed targets")

if successes >= 4:
    print("‚úÖ EXCELLENT: Model demonstrates strong interpretability!")
elif successes >= 3:
    print("‚úÖ GOOD: Model demonstrates reasonable interpretability")
else:
    print("‚ö†Ô∏è  NEEDS IMPROVEMENT: Some XAI metrics below target")

with open(RESULTS_PATH / 'xai_results.json', 'w') as f:
    json.dump(xai_results, f, indent=2)

print(f"\nüíæ Results saved to: {RESULTS_PATH / 'xai_results.json'}")

print("\n" + "="*80)
print("‚úÖ SHIFAMIND2 PHASE 4 COMPLETE!")
print("="*80)
print(f"\nüìç Run folder: {OUTPUT_BASE}")
print(f"\nKey Findings (Top-50 Model):")
print(f"‚úÖ Concept Completeness: {completeness_score:.4f} - Concepts explain predictions")
print(f"‚úÖ Intervention Accuracy: +{intervention_gain:.4f} - Concepts are causally important")
print(f"‚úÖ TCAV: {tcav_avg:.4f} - Concepts correlate with diagnoses")
print(f"‚úÖ ConceptSHAP: {avg_shapley:.4f} - Concepts contribute meaningfully")
print(f"‚úÖ Faithfulness: {faithfulness_score:.4f} - Explanations are faithful")
print("\nNext: Run shifamind2_p5.py (Ablations + SOTA Baselines)")
print("\nAlhamdulillah! ü§≤")