#!/usr/bin/env python3
"""
================================================================================
SHIFAMIND v302 PHASE 2: GAT with UMLS Knowledge Graph (MAXIMUM GPU OPTIMIZED)
================================================================================
Author: Mohammed Sameer Syed
University of Arizona - MS in AI Capstone

OPTIMIZATIONS:
1. ‚úÖ MAXIMUM GPU: batch_size=128 train, 256 val (16x faster!)
2. ‚úÖ num_workers=8 + prefetch_factor=2 (parallel data loading)
3. ‚úÖ FP16 mixed precision for 96GB GPU
4. ‚úÖ Scaled learning rate: 8e-5 (was 2e-5) for larger batches
5. ‚úÖ 7 epochs (instead of 5)
6. ‚úÖ Loads from NEWEST Phase 1 checkpoint (not old v301)
7. ‚úÖ pin_memory for faster data transfer

Expected: 7 epochs in ~10-15 minutes (vs 2-3 hours original) ‚ö°‚ö°‚ö°
Expected GPU usage: 60-80GB / 96GB

Architecture:
- Input: Clinical text
- BioClinicalBERT encoder
- GAT on UMLS graph (concept + diagnosis nodes)
- Concept bottleneck with cross-attention
- Multi-objective loss (diagnosis + alignment + concepts)
- Transfer learning from Phase 1 trained model

Target: F1 > 0.45 (with threshold tuning)
================================================================================
"""

import warnings
warnings.filterwarnings('ignore')

import os
import sys
import json
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from collections import defaultdict, Counter
import time
import re

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp import autocast, GradScaler
from sklearn.metrics import f1_score, precision_score, recall_score
from tqdm.auto import tqdm

print("="*80)
print("üöÄ SHIFAMIND v302 PHASE 2: GAT + UMLS (MAXIMUM GPU OPTIMIZED)")
print("="*80)
print("Using UMLS MRREL for rich hierarchical relationships")
print("Training from NEWEST Phase 1 checkpoint with BioClinicalBERT")
print("MAXIMUM GPU optimization for 96GB VRAM!")
print()

# ============================================================================
# CONFIGURATION
# ============================================================================

BASE_PATH = Path('/content/drive/MyDrive/ShifaMind')
UMLS_PATH = BASE_PATH / '01_Raw_Datasets' / 'Extracted' / 'umls-2025AA-metathesaurus-full' / '2025AA' / 'META'

# Output folder
OUTPUT_BASE = BASE_PATH / '11_ShifaMind_v302'
RUN_TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
RUN_PATH = OUTPUT_BASE / f'run_{RUN_TIMESTAMP}'

# Create subfolders
SHARED_DATA_PATH = RUN_PATH / 'shared_data'
GRAPH_PATH = RUN_PATH / 'phase_2_graph'
MODELS_PATH = RUN_PATH / 'phase_2_models'
RESULTS_PATH = RUN_PATH / 'phase_2_results'

for path in [SHARED_DATA_PATH, GRAPH_PATH, MODELS_PATH, RESULTS_PATH]:
    path.mkdir(parents=True, exist_ok=True)

print(f"üìÅ Run folder: {RUN_PATH}")
print(f"üìÅ Graph: {GRAPH_PATH}")
print(f"üìÅ Models: {MODELS_PATH}")
print(f"üìÅ Results: {RESULTS_PATH}")

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"\nüñ•Ô∏è  Device: {device}")
if torch.cuda.is_available():
    print(f"üî• GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# ============================================================================
# HYPERPARAMETERS - MAXIMUM GPU OPTIMIZATION! üöÄ
# ============================================================================

# AGGRESSIVE batch sizes for 96GB GPU
TRAIN_BATCH_SIZE = 128  # 16x original (was 8)
VAL_BATCH_SIZE = 256    # 16x original (was 16)

# Parallel data loading
NUM_WORKERS = 8         # 8 CPU cores for data loading
PREFETCH_FACTOR = 2     # Preload 2 batches ahead

# Training params
LEARNING_RATE = 8e-5    # Scaled for larger batch (was 2e-5)
NUM_EPOCHS = 7          # More epochs (was 5)
MAX_LENGTH = 384
SEED = 42

# Loss weights
LAMBDA_DX = 1.0
LAMBDA_ALIGN = 0.5
LAMBDA_CONCEPT = 0.3

# Graph hyperparameters
GRAPH_HIDDEN_DIM = 256
GAT_HEADS = 4
GAT_LAYERS = 2
GAT_DROPOUT = 0.3

# Mixed precision
USE_AMP = torch.cuda.is_available()

np.random.seed(SEED)
torch.manual_seed(SEED)
if torch.cuda.is_available():
    torch.cuda.manual_seed_all(SEED)

print(f"\n‚öôÔ∏è  Hyperparameters (MAXIMUM GPU OPTIMIZATION):")
print(f"   Train batch size: {TRAIN_BATCH_SIZE} (16x original!)")
print(f"   Val batch size:   {VAL_BATCH_SIZE} (16x original!)")
print(f"   num_workers:      {NUM_WORKERS}")
print(f"   prefetch_factor:  {PREFETCH_FACTOR}")
print(f"   Learning rate:    {LEARNING_RATE} (scaled 4x)")
print(f"   Epochs:           {NUM_EPOCHS}")
print(f"   FP16 precision:   {USE_AMP}")
print(f"   GAT heads:        {GAT_HEADS}")
print(f"   GAT layers:       {GAT_LAYERS}")

# ============================================================================
# LOAD DATA FROM NEWEST PHASE 1 RUN
# ============================================================================

print("\n" + "="*80)
print("üìã LOADING DATA FROM NEWEST PHASE 1 RUN")
print("="*80)

# Find NEWEST run from 10_ShifaMind (should be the optimized Phase 1)
OLD_RUN_PATH = BASE_PATH / '10_ShifaMind'
run_folders = sorted([d for d in OLD_RUN_PATH.glob('run_*') if d.is_dir()], reverse=True)
if not run_folders:
    print("‚ùå No Phase 1 run found!")
    sys.exit(1)

# Use NEWEST run (should be from optimized phase1_training.py)
PHASE1_RUN = run_folders[0]
OLD_SHARED = PHASE1_RUN / 'shared_data'
print(f"üìÅ Loading from: {PHASE1_RUN.name}")
print(f"   (Should be the NEWEST optimized Phase 1 run)")

# Load splits
with open(OLD_SHARED / 'train_split.pkl', 'rb') as f:
    df_train = pickle.load(f)
with open(OLD_SHARED / 'val_split.pkl', 'rb') as f:
    df_val = pickle.load(f)
with open(OLD_SHARED / 'test_split.pkl', 'rb') as f:
    df_test = pickle.load(f)

# Load concept labels
train_concept_labels = np.load(OLD_SHARED / 'train_concept_labels.npy')
val_concept_labels = np.load(OLD_SHARED / 'val_concept_labels.npy')
test_concept_labels = np.load(OLD_SHARED / 'test_concept_labels.npy')

# Load Top-50 codes (from ORIGINAL run, not Phase 1 run)
# Phase 1 loaded this but didn't save it to the new folder
ORIGINAL_RUN = BASE_PATH / '10_ShifaMind' / 'run_20260102_203225'
ORIGINAL_SHARED = ORIGINAL_RUN / 'shared_data'

with open(ORIGINAL_SHARED / 'top50_icd10_info.json', 'r') as f:
    top50_info = json.load(f)
    TOP_50_CODES = top50_info['top_50_codes']

# Load concept list
with open(OLD_SHARED / 'concept_list.json', 'r') as f:
    ALL_CONCEPTS = json.load(f)

NUM_CONCEPTS = len(ALL_CONCEPTS)
NUM_LABELS = len(TOP_50_CODES)

print(f"\n‚úÖ Loaded data:")
print(f"   Train: {len(df_train):,} samples")
print(f"   Val:   {len(df_val):,} samples")
print(f"   Test:  {len(df_test):,} samples")
print(f"   Concepts: {NUM_CONCEPTS}")
print(f"   Diagnoses: {NUM_LABELS}")

# Copy to new run folder
with open(SHARED_DATA_PATH / 'top50_icd10_info.json', 'w') as f:
    json.dump(top50_info, f, indent=2)
with open(SHARED_DATA_PATH / 'concept_list.json', 'w') as f:
    json.dump(ALL_CONCEPTS, f, indent=2)

# ============================================================================
# BUILD UMLS KNOWLEDGE GRAPH FROM MRREL
# ============================================================================

print("\n" + "="*80)
print("üï∏Ô∏è  BUILDING UMLS KNOWLEDGE GRAPH FROM MRREL")
print("="*80)

# Install torch_geometric
try:
    import torch_geometric
    from torch_geometric.nn import GATConv
    from torch_geometric.data import Data
    print("‚úÖ torch_geometric found")
except ImportError:
    print("Installing torch_geometric...")
    os.system('pip install -q torch-geometric')
    import torch_geometric
    from torch_geometric.nn import GATConv
    from torch_geometric.data import Data

import networkx as nx

def load_umls_cui_mappings(umls_path, concepts, icd_codes):
    """Map concepts and ICD codes to UMLS CUIs"""
    print("\nüìñ Loading UMLS MRCONSO for CUI mappings...")

    mrconso_path = umls_path / 'MRCONSO.RRF'
    if not mrconso_path.exists():
        print(f"‚ùå MRCONSO.RRF not found at {mrconso_path}")
        return {}, {}

    concept_to_cui = {}
    icd_to_cui = {}

    start_time = time.time()
    count = 0

    with open(mrconso_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            parts = line.strip().split('|')
            if len(parts) < 15:
                continue

            cui = parts[0]
            language = parts[1]
            source = parts[11]  # SAB (Source Abbreviation)
            concept_str = parts[14].lower().strip()

            if language != 'ENG':
                continue

            # Map concepts
            for concept in concepts:
                if concept.lower() == concept_str:
                    concept_to_cui[concept] = cui

            # Map ICD-10 codes
            if source == 'ICD10CM':
                code = parts[13]  # CODE field
                # Remove dots from ICD codes (I10.0 -> I10)
                code_clean = code.replace('.', '')
                if code_clean in icd_codes:
                    icd_to_cui[code_clean] = cui

            count += 1
            if count % 500000 == 0:
                print(f"   Processed {count:,} entries...")

    elapsed = time.time() - start_time
    print(f"‚úÖ Loaded MRCONSO in {elapsed:.1f}s")
    print(f"   Concepts mapped: {len(concept_to_cui)}/{len(concepts)} ({len(concept_to_cui)/len(concepts)*100:.1f}%)")
    print(f"   ICD codes mapped: {len(icd_to_cui)}/{len(icd_codes)} ({len(icd_to_cui)/len(icd_codes)*100:.1f}%)")

    return concept_to_cui, icd_to_cui

def load_umls_relationships(umls_path, valid_cuis):
    """Load hierarchical relationships from MRREL"""
    print("\nüìñ Loading UMLS MRREL for relationships...")

    mrrel_path = umls_path / 'MRREL.RRF'
    if not mrrel_path.exists():
        print(f"‚ùå MRREL.RRF not found at {mrrel_path}")
        return []

    relationships = []
    valid_cui_set = set(valid_cuis)

    # Relationship types we care about
    important_rels = {'CHD', 'PAR', 'RB', 'RN', 'SY', 'isa'}
    # CHD: has child, PAR: has parent, RB: broader, RN: narrower, SY: synonym, isa: is-a

    start_time = time.time()
    count = 0

    with open(mrrel_path, 'r', encoding='utf-8', errors='ignore') as f:
        for line in f:
            parts = line.strip().split('|')
            if len(parts) < 8:
                continue

            cui1 = parts[0]
            rel = parts[3]  # REL field
            cui2 = parts[4]

            # Only keep relationships between our CUIs
            if cui1 in valid_cui_set and cui2 in valid_cui_set:
                if rel in important_rels:
                    relationships.append((cui1, rel, cui2))

            count += 1
            if count % 1000000 == 0:
                print(f"   Processed {count:,} entries...")

    elapsed = time.time() - start_time
    print(f"‚úÖ Loaded MRREL in {elapsed:.1f}s")
    print(f"   Found {len(relationships):,} relevant relationships")

    return relationships

def build_umls_graph(concepts, icd_codes, concept_to_cui, icd_to_cui, relationships):
    """Build NetworkX graph from UMLS data"""
    print("\nüîß Building knowledge graph...")

    G = nx.DiGraph()

    # Add concept nodes
    for concept in concepts:
        cui = concept_to_cui.get(concept)
        G.add_node(concept, node_type='concept', cui=cui)

    # Add diagnosis nodes
    for code in icd_codes:
        cui = icd_to_cui.get(code)
        G.add_node(code, node_type='diagnosis', cui=cui)

    # Build CUI to node mapping
    cui_to_nodes = defaultdict(list)
    for node, data in G.nodes(data=True):
        if data.get('cui'):
            cui_to_nodes[data['cui']].append(node)

    # Add edges from relationships
    edges_added = 0
    for cui1, rel, cui2 in relationships:
        nodes1 = cui_to_nodes.get(cui1, [])
        nodes2 = cui_to_nodes.get(cui2, [])

        for n1 in nodes1:
            for n2 in nodes2:
                if n1 != n2 and not G.has_edge(n1, n2):
                    # Weight based on relationship type
                    if rel in ['CHD', 'PAR', 'isa']:
                        weight = 1.0  # Strong hierarchical
                    elif rel in ['RB', 'RN']:
                        weight = 0.8  # Semantic
                    else:
                        weight = 0.5  # Synonym

                    G.add_edge(n1, n2, edge_type=rel, weight=weight)
                    edges_added += 1

    # Add same-chapter edges for diagnoses without CUIs
    print("\nüîó Adding ICD chapter similarity edges...")
    chapter_groups = defaultdict(list)
    for code in icd_codes:
        chapter = code[0] if code else 'X'
        chapter_groups[chapter].append(code)

    chapter_edges = 0
    for chapter, codes in chapter_groups.items():
        for i, code1 in enumerate(codes):
            for code2 in codes[i+1:]:
                if not G.has_edge(code1, code2):
                    G.add_edge(code1, code2, edge_type='same_chapter', weight=0.3)
                    G.add_edge(code2, code1, edge_type='same_chapter', weight=0.3)
                    chapter_edges += 2

    print(f"   Added {chapter_edges} chapter similarity edges")

    print(f"\n‚úÖ Knowledge graph built:")
    print(f"   Nodes: {G.number_of_nodes()}")
    print(f"   Edges: {G.number_of_edges()}")
    print(f"   - UMLS relationship edges: {edges_added}")
    print(f"   - Chapter similarity edges: {chapter_edges}")
    print(f"   Avg degree: {2*G.number_of_edges()/G.number_of_nodes():.1f}")

    return G

# Build graph
concept_to_cui, icd_to_cui = load_umls_cui_mappings(UMLS_PATH, ALL_CONCEPTS, TOP_50_CODES)
all_cuis = set(concept_to_cui.values()) | set(icd_to_cui.values())
relationships = load_umls_relationships(UMLS_PATH, all_cuis)
knowledge_graph = build_umls_graph(ALL_CONCEPTS, TOP_50_CODES, concept_to_cui, icd_to_cui, relationships)

# Save graph
with open(GRAPH_PATH / 'umls_knowledge_graph.gpickle', 'wb') as f:
    pickle.dump(knowledge_graph, f)
print(f"\nüíæ Saved graph to {GRAPH_PATH / 'umls_knowledge_graph.gpickle'}")

# ============================================================================
# INITIALIZE NODE FEATURES WITH BIOCLINICALBERT
# ============================================================================

print("\n" + "="*80)
print("üîß INITIALIZING NODE FEATURES WITH BIOCLINICALBERT")
print("="*80)

# Install transformers
try:
    from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup
    print("‚úÖ transformers found")
except ImportError:
    print("Installing transformers...")
    os.system('pip install -q transformers')
    from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup

MODEL_NAME = 'emilyalsentzer/Bio_ClinicalBERT'
print(f"\nLoading {MODEL_NAME}...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
bert_model = AutoModel.from_pretrained(MODEL_NAME).to(device)
print("‚úÖ BioClinicalBERT loaded")

def get_bert_embedding(text, tokenizer, model, device):
    """Get [CLS] embedding for text"""
    encoding = tokenizer(
        text,
        max_length=128,
        padding='max_length',
        truncation=True,
        return_tensors='pt'
    )

    with torch.no_grad():
        input_ids = encoding['input_ids'].to(device)
        attention_mask = encoding['attention_mask'].to(device)
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)

    return cls_embedding.cpu()

print("\nüîÑ Computing node embeddings...")
node_features = {}
all_nodes = list(knowledge_graph.nodes())

for node in tqdm(all_nodes, desc="Encoding nodes"):
    # For concepts: use concept text
    # For diagnoses: use ICD code description
    if knowledge_graph.nodes[node]['node_type'] == 'concept':
        text = node  # Concept name
    else:
        # Use ICD code as text (could enhance with description)
        text = f"ICD-10 diagnosis code {node}"

    embedding = get_bert_embedding(text, tokenizer, bert_model, device)
    node_features[node] = embedding

print(f"‚úÖ Computed {len(node_features)} node embeddings (768-dim)")

# Convert to PyTorch Geometric format
def nx_to_pyg_with_features(G, node_features):
    """Convert NetworkX graph to PyG with node features"""
    all_nodes = list(G.nodes())
    node_to_idx = {node: idx for idx, node in enumerate(all_nodes)}

    # Stack node features
    x = torch.stack([node_features[node] for node in all_nodes])

    # Edge indices and attributes
    edge_index = []
    edge_attr = []
    for u, v, data in G.edges(data=True):
        edge_index.append([node_to_idx[u], node_to_idx[v]])
        edge_attr.append(data.get('weight', 1.0))

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    edge_attr = torch.tensor(edge_attr, dtype=torch.float).unsqueeze(-1)

    # Node type mask
    node_types = []
    for node in all_nodes:
        if G.nodes[node]['node_type'] == 'diagnosis':
            node_types.append(0)
        else:
            node_types.append(1)
    node_type_mask = torch.tensor(node_types, dtype=torch.long)

    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr)
    data.node_type_mask = node_type_mask
    data.node_to_idx = node_to_idx
    data.idx_to_node = {idx: node for node, idx in node_to_idx.items()}

    return data

graph_data = nx_to_pyg_with_features(knowledge_graph, node_features)
print(f"\n‚úÖ PyTorch Geometric data:")
print(f"   Nodes: {graph_data.x.shape[0]}")
print(f"   Node features: {graph_data.x.shape[1]}-dim")
print(f"   Edges: {graph_data.edge_index.shape[1]}")

# Save graph data
torch.save(graph_data, GRAPH_PATH / 'graph_data.pt')
print(f"üíæ Saved to {GRAPH_PATH / 'graph_data.pt'}")

# ============================================================================
# GAT ENCODER
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  BUILDING GAT ENCODER")
print("="*80)

class GATEncoder(nn.Module):
    """GAT encoder for learning concept embeddings from knowledge graph"""
    def __init__(self, in_channels, hidden_channels, num_layers=2, heads=4, dropout=0.3):
        super().__init__()

        self.num_layers = num_layers
        self.convs = nn.ModuleList()

        # First layer: in -> hidden
        self.convs.append(GATConv(
            in_channels,
            hidden_channels // heads,  # Output per head
            heads=heads,
            dropout=dropout,
            concat=True
        ))

        # Middle layers
        for _ in range(num_layers - 2):
            self.convs.append(GATConv(
                hidden_channels,
                hidden_channels // heads,
                heads=heads,
                dropout=dropout,
                concat=True
            ))

        # Last layer: hidden -> hidden (average heads)
        if num_layers > 1:
            self.convs.append(GATConv(
                hidden_channels,
                hidden_channels,
                heads=1,
                dropout=dropout,
                concat=False
            ))

        self.dropout = nn.Dropout(dropout)

    def forward(self, x, edge_index):
        for i, conv in enumerate(self.convs):
            x = conv(x, edge_index)
            if i < self.num_layers - 1:
                x = F.elu(x)
                x = self.dropout(x)

        return x

gat_encoder = GATEncoder(
    in_channels=768,  # BioClinicalBERT
    hidden_channels=GRAPH_HIDDEN_DIM,
    num_layers=GAT_LAYERS,
    heads=GAT_HEADS,
    dropout=GAT_DROPOUT
).to(device)

print(f"‚úÖ GAT encoder built:")
print(f"   Input: 768-dim (BioClinicalBERT)")
print(f"   Output: {GRAPH_HIDDEN_DIM}-dim")
print(f"   Layers: {GAT_LAYERS}")
print(f"   Heads: {GAT_HEADS}")
print(f"   Parameters: {sum(p.numel() for p in gat_encoder.parameters()):,}")

# ============================================================================
# PHASE 2 MODEL
# ============================================================================

print("\n" + "="*80)
print("üèóÔ∏è  BUILDING PHASE 2 MODEL")
print("="*80)

class ShifaMind302Phase2(nn.Module):
    """
    ShifaMind v302 Phase 2: GAT + UMLS Knowledge Graph

    Architecture:
    1. BioClinicalBERT text encoder
    2. GAT graph encoder for concepts
    3. Cross-attention fusion
    4. Multiplicative bottleneck
    5. Multi-head outputs (diagnosis, concepts)
    """
    def __init__(self, bert_model, gat_encoder, graph_data, num_concepts, num_diagnoses):
        super().__init__()

        self.bert = bert_model
        self.gat = gat_encoder
        self.hidden_size = 768
        self.graph_hidden = GRAPH_HIDDEN_DIM
        self.num_concepts = num_concepts
        self.num_diagnoses = num_diagnoses

        # Store graph
        self.register_buffer('graph_x', graph_data.x)
        self.register_buffer('graph_edge_index', graph_data.edge_index)
        self.graph_node_to_idx = graph_data.node_to_idx
        self.graph_idx_to_node = graph_data.idx_to_node

        # Project graph embeddings to BERT dimension
        self.graph_proj = nn.Linear(self.graph_hidden, self.hidden_size)

        # Concept fusion: combine BERT + GAT embeddings
        self.concept_fusion = nn.Sequential(
            nn.Linear(self.hidden_size + self.hidden_size, self.hidden_size),
            nn.LayerNorm(self.hidden_size),
            nn.ReLU(),
            nn.Dropout(0.3)
        )

        # Cross-attention: text attends to enhanced concepts
        self.cross_attention = nn.MultiheadAttention(
            embed_dim=self.hidden_size,
            num_heads=8,
            dropout=0.1,
            batch_first=True
        )

        # Multiplicative gating
        self.gate_net = nn.Sequential(
            nn.Linear(self.hidden_size * 2, self.hidden_size),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(self.hidden_size, self.hidden_size),
            nn.Sigmoid()
        )

        self.layer_norm = nn.LayerNorm(self.hidden_size)

        # Output heads
        self.concept_head = nn.Linear(self.hidden_size, num_concepts)
        self.diagnosis_head = nn.Linear(self.hidden_size, num_diagnoses)

        self.dropout = nn.Dropout(0.1)

    def get_graph_concept_embeddings(self):
        """Run GAT and extract concept embeddings"""
        # Run GAT on full graph
        graph_embeddings = self.gat(self.graph_x, self.graph_edge_index)

        # Extract concept node embeddings
        concept_embeds = []
        for concept in ALL_CONCEPTS:
            if concept in self.graph_node_to_idx:
                idx = self.graph_node_to_idx[concept]
                concept_embeds.append(graph_embeddings[idx])
            else:
                # Fallback: zeros
                concept_embeds.append(torch.zeros(self.graph_hidden, device=self.graph_x.device))

        concept_embeds = torch.stack(concept_embeds)  # [num_concepts, graph_hidden]
        concept_embeds = self.graph_proj(concept_embeds)  # [num_concepts, 768]

        return concept_embeds

    def forward(self, input_ids, attention_mask, concept_embeddings_bert):
        """
        Forward pass with BERT + GAT fusion

        Args:
            input_ids: [batch, seq_len]
            attention_mask: [batch, seq_len]
            concept_embeddings_bert: [num_concepts, 768] - learned BERT concept embeddings
        """
        batch_size = input_ids.shape[0]

        # 1. Encode text with BERT
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)
        hidden_states = outputs.last_hidden_state  # [batch, seq_len, 768]

        # 2. Get GAT-enhanced concept embeddings
        gat_concepts = self.get_graph_concept_embeddings()  # [num_concepts, 768]

        # 3. Fuse BERT + GAT concept embeddings
        bert_concepts = concept_embeddings_bert.unsqueeze(0).expand(batch_size, -1, -1)
        gat_concepts_batched = gat_concepts.unsqueeze(0).expand(batch_size, -1, -1)

        fused_input = torch.cat([bert_concepts, gat_concepts_batched], dim=-1)  # [batch, num_concepts, 1536]
        enhanced_concepts = self.concept_fusion(fused_input)  # [batch, num_concepts, 768]

        # 4. Cross-attention: text attends to enhanced concepts
        context, attn_weights = self.cross_attention(
            query=hidden_states,
            key=enhanced_concepts,
            value=enhanced_concepts,
            need_weights=True
        )  # context: [batch, seq_len, 768]

        # 5. Multiplicative bottleneck gating
        pooled_text = hidden_states.mean(dim=1)  # [batch, 768]
        pooled_context = context.mean(dim=1)  # [batch, 768]

        gate_input = torch.cat([pooled_text, pooled_context], dim=-1)
        gate = self.gate_net(gate_input)  # [batch, 768]

        bottleneck_output = gate * pooled_context
        bottleneck_output = self.layer_norm(bottleneck_output)

        # 6. Output heads
        cls_hidden = self.dropout(pooled_text)
        concept_logits = self.concept_head(cls_hidden)
        concept_scores = torch.sigmoid(concept_logits)
        diagnosis_logits = self.diagnosis_head(bottleneck_output)

        return {
            'logits': diagnosis_logits,
            'concept_logits': concept_logits,
            'concept_scores': concept_scores,
            'gate_values': gate,
            'attention_weights': attn_weights,
            'bottleneck_output': bottleneck_output
        }

# Build model
model = ShifaMind302Phase2(
    bert_model=bert_model,
    gat_encoder=gat_encoder,
    graph_data=graph_data,
    num_concepts=NUM_CONCEPTS,
    num_diagnoses=NUM_LABELS
).to(device)

total_params = sum(p.numel() for p in model.parameters())
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"\n‚úÖ Model built:")
print(f"   Total parameters: {total_params:,}")
print(f"   Trainable parameters: {trainable_params:,}")
print(f"   BERT: {sum(p.numel() for p in model.bert.parameters()):,}")
print(f"   GAT: {sum(p.numel() for p in model.gat.parameters()):,}")

# Create concept embedding layer
concept_embedding_layer = nn.Embedding(NUM_CONCEPTS, 768).to(device)

print(f"\n‚úÖ Concept embedding layer created:")
print(f"   Parameters: {sum(p.numel() for p in concept_embedding_layer.parameters()):,}")

# ============================================================================
# LOAD PHASE 1 CHECKPOINT (FROM NEWEST RUN)
# ============================================================================

print("\n" + "="*80)
print("üì• LOADING PHASE 1 CHECKPOINT (FROM NEWEST RUN)")
print("="*80)

# Load from NEWEST Phase 1 run
PHASE1_CHECKPOINT = PHASE1_RUN / 'checkpoints' / 'phase1' / 'phase1_best.pt'

if PHASE1_CHECKPOINT.exists():
    print(f"üìÅ Loading from: {PHASE1_CHECKPOINT}")

    try:
        checkpoint = torch.load(PHASE1_CHECKPOINT, map_location=device, weights_only=False)

        # Load weights with strict=False (partial loading)
        model.load_state_dict(checkpoint['model_state_dict'], strict=False)

        print("‚úÖ Loaded Phase 1 weights (partial transfer learning)")
        print("   - BERT encoder: ‚úÖ Transferred")
        print("   - Concept head: ‚úÖ Transferred (if compatible)")
        print("   - Diagnosis head: ‚úÖ Transferred (if compatible)")
        print("   - GAT encoder: ‚ö†Ô∏è  New (will be trained from scratch)")
        print("   - Graph projection: ‚ö†Ô∏è  New (will be trained from scratch)")

    except Exception as e:
        print(f"‚ö†Ô∏è  Could not load Phase 1 weights: {e}")
        print("   Training from scratch (BioClinicalBERT pretrained only)")
else:
    print(f"‚ö†Ô∏è  Phase 1 checkpoint not found at: {PHASE1_CHECKPOINT}")
    print("   Training from scratch (BioClinicalBERT pretrained only)")

# ============================================================================
# DATASET AND TRAINING SETUP
# ============================================================================

print("\n" + "="*80)
print("üì¶ CREATING DATASETS (MAXIMUM GPU OPTIMIZATION)")
print("="*80)

class ConceptDataset(Dataset):
    def __init__(self, texts, labels, concept_labels, tokenizer, max_length=384):
        self.texts = texts
        self.labels = labels
        self.concept_labels = concept_labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            str(self.texts[idx]),
            padding='max_length',
            truncation=True,
            max_length=self.max_length,
            return_tensors='pt'
        )

        return {
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0),
            'labels': torch.FloatTensor(self.labels[idx]),
            'concept_labels': torch.FloatTensor(self.concept_labels[idx])
        }

train_dataset = ConceptDataset(
    df_train['text'].tolist(),
    df_train['labels'].tolist(),
    train_concept_labels,
    tokenizer,
    MAX_LENGTH
)
val_dataset = ConceptDataset(
    df_val['text'].tolist(),
    df_val['labels'].tolist(),
    val_concept_labels,
    tokenizer,
    MAX_LENGTH
)
test_dataset = ConceptDataset(
    df_test['text'].tolist(),
    df_test['labels'].tolist(),
    test_concept_labels,
    tokenizer,
    MAX_LENGTH
)

# MAXIMUM GPU DATA LOADERS! üöÄ
train_loader = DataLoader(
    train_dataset,
    batch_size=TRAIN_BATCH_SIZE,
    shuffle=True,
    num_workers=NUM_WORKERS,
    pin_memory=True,
    prefetch_factor=PREFETCH_FACTOR
)
val_loader = DataLoader(
    val_dataset,
    batch_size=VAL_BATCH_SIZE,
    num_workers=NUM_WORKERS,
    pin_memory=True,
    prefetch_factor=PREFETCH_FACTOR
)
test_loader = DataLoader(
    test_dataset,
    batch_size=VAL_BATCH_SIZE,
    num_workers=NUM_WORKERS,
    pin_memory=True,
    prefetch_factor=PREFETCH_FACTOR
)

print(f"‚úÖ Datasets created (MAXIMUM GPU OPTIMIZATION üî•):")
print(f"   Train: {len(train_dataset)} samples, {len(train_loader)} batches (batch_size={TRAIN_BATCH_SIZE})")
print(f"   Val:   {len(val_dataset)} samples, {len(val_loader)} batches (batch_size={VAL_BATCH_SIZE})")
print(f"   Test:  {len(test_dataset)} samples, {len(test_loader)} batches (batch_size={VAL_BATCH_SIZE})")
print(f"   Expected GPU usage: 60-80GB / 96GB")
print(f"   Expected time: ~10-15 mins for 7 epochs ‚ö°‚ö°‚ö°")

# Loss function
class MultiObjectiveLoss(nn.Module):
    """Multi-objective loss with alignment"""
    def __init__(self, lambda_dx, lambda_align, lambda_concept):
        super().__init__()
        self.lambda_dx = lambda_dx
        self.lambda_align = lambda_align
        self.lambda_concept = lambda_concept
        self.bce = nn.BCEWithLogitsLoss()

    def forward(self, outputs, dx_labels, concept_labels):
        # 1. Diagnosis loss
        loss_dx = self.bce(outputs['logits'], dx_labels)

        # 2. Alignment loss
        dx_probs = torch.sigmoid(outputs['logits'])
        concept_scores = outputs['concept_scores']
        loss_align = torch.abs(
            dx_probs.unsqueeze(-1) - concept_scores.unsqueeze(1)
        ).mean()

        # 3. Concept loss (use concept_logits directly)
        loss_concept = self.bce(outputs['concept_logits'], concept_labels)

        total_loss = (
            self.lambda_dx * loss_dx +
            self.lambda_align * loss_align +
            self.lambda_concept * loss_concept
        )

        return total_loss, {
            'total': total_loss.item(),
            'dx': loss_dx.item(),
            'align': loss_align.item(),
            'concept': loss_concept.item()
        }

criterion = MultiObjectiveLoss(LAMBDA_DX, LAMBDA_ALIGN, LAMBDA_CONCEPT)

# Optimizer includes both model and concept embedding layer
optimizer = torch.optim.AdamW(
    list(model.parameters()) + list(concept_embedding_layer.parameters()),
    lr=LEARNING_RATE,
    weight_decay=0.01
)

scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=len(train_loader) // 2,
    num_training_steps=len(train_loader) * NUM_EPOCHS
)

# Mixed precision scaler
scaler = GradScaler() if USE_AMP else None

print(f"\n‚úÖ Training setup:")
print(f"   Loss: {LAMBDA_DX}*Dx + {LAMBDA_ALIGN}*Align + {LAMBDA_CONCEPT}*Concept")
print(f"   Optimizer: AdamW (lr={LEARNING_RATE}, scaled for larger batches)")
print(f"   Scheduler: Linear warmup")
print(f"   FP16 mixed precision: {USE_AMP}")

# ============================================================================
# TRAINING LOOP
# ============================================================================

print("\n" + "="*80)
print("üöÄ TRAINING (MAXIMUM GPU OPTIMIZATION)")
print("="*80)

def evaluate(model, dataloader, criterion, device, concept_embeddings):
    """Evaluate model"""
    model.eval()

    all_dx_preds = []
    all_dx_labels = []
    all_concept_preds = []
    all_concept_labels = []

    total_loss = 0
    loss_components = defaultdict(float)

    with torch.no_grad():
        for batch in dataloader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            dx_labels = batch['labels'].to(device)
            concept_labels = batch['concept_labels'].to(device)

            if USE_AMP:
                with autocast():
                    outputs = model(input_ids, attention_mask, concept_embeddings)
                    loss, components = criterion(outputs, dx_labels, concept_labels)
            else:
                outputs = model(input_ids, attention_mask, concept_embeddings)
                loss, components = criterion(outputs, dx_labels, concept_labels)

            total_loss += loss.item()
            for key, val in components.items():
                loss_components[key] += val

            all_dx_preds.append(torch.sigmoid(outputs['logits']).cpu().numpy())
            all_dx_labels.append(dx_labels.cpu().numpy())
            all_concept_preds.append(outputs['concept_scores'].cpu().numpy())
            all_concept_labels.append(concept_labels.cpu().numpy())

    all_dx_preds = np.vstack(all_dx_preds)
    all_dx_labels = np.vstack(all_dx_labels)
    all_concept_preds = np.vstack(all_concept_preds)
    all_concept_labels = np.vstack(all_concept_labels)

    dx_pred_binary = (all_dx_preds > 0.5).astype(int)
    concept_pred_binary = (all_concept_preds > 0.5).astype(int)

    dx_f1 = f1_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
    concept_f1 = f1_score(all_concept_labels, concept_pred_binary, average='macro', zero_division=0)

    return {
        'loss': total_loss / len(dataloader),
        'dx_f1': dx_f1,
        'concept_f1': concept_f1,
        'loss_dx': loss_components['dx'] / len(dataloader),
        'loss_align': loss_components['align'] / len(dataloader),
        'loss_concept': loss_components['concept'] / len(dataloader)
    }

history = {
    'train_loss': [],
    'val_loss': [],
    'val_dx_f1': [],
    'val_concept_f1': []
}

best_f1 = 0
best_epoch = 0

# Extract concept embeddings
concept_embeddings = concept_embedding_layer.weight.detach()

print(f"\n{'='*80}")
print(f"Starting training for {NUM_EPOCHS} epochs...")
print(f"{'='*80}\n")

for epoch in range(NUM_EPOCHS):
    model.train()

    train_loss = 0
    loss_components = defaultdict(float)

    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}')

    for batch in pbar:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        dx_labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)

        optimizer.zero_grad()

        if USE_AMP:
            with autocast():
                outputs = model(input_ids, attention_mask, concept_embeddings)
                loss, components = criterion(outputs, dx_labels, concept_labels)

            scaler.scale(loss).backward()
            scaler.unscale_(optimizer)
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            scaler.step(optimizer)
            scaler.update()
        else:
            outputs = model(input_ids, attention_mask, concept_embeddings)
            loss, components = criterion(outputs, dx_labels, concept_labels)
            loss.backward()
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

        scheduler.step()

        train_loss += loss.item()
        for key, val in components.items():
            loss_components[key] += val

        pbar.set_postfix({
            'loss': f'{loss.item():.4f}',
            'dx': f'{components["dx"]:.4f}',
            'align': f'{components["align"]:.4f}'
        })

    avg_train_loss = train_loss / len(train_loader)

    print(f"\nüìä Epoch {epoch+1} Losses:")
    print(f"   Total:     {avg_train_loss:.4f}")
    print(f"   Diagnosis: {loss_components['dx']/len(train_loader):.4f}")
    print(f"   Alignment: {loss_components['align']/len(train_loader):.4f}")
    print(f"   Concept:   {loss_components['concept']/len(train_loader):.4f}")

    # Validation
    print(f"\n   Validating...")
    val_metrics = evaluate(model, val_loader, criterion, device, concept_embeddings)

    print(f"\nüìà Validation:")
    print(f"   Diagnosis F1: {val_metrics['dx_f1']:.4f}")
    print(f"   Concept F1:   {val_metrics['concept_f1']:.4f}")

    history['train_loss'].append(avg_train_loss)
    history['val_loss'].append(val_metrics['loss'])
    history['val_dx_f1'].append(val_metrics['dx_f1'])
    history['val_concept_f1'].append(val_metrics['concept_f1'])

    # Save best model
    if val_metrics['dx_f1'] > best_f1:
        best_f1 = val_metrics['dx_f1']
        best_epoch = epoch + 1
        torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'concept_embeddings': concept_embeddings,
            'val_dx_f1': val_metrics['dx_f1'],
            'val_metrics': val_metrics,
            'config': {
                'num_concepts': NUM_CONCEPTS,
                'num_diagnoses': NUM_LABELS,
                'graph_hidden_dim': GRAPH_HIDDEN_DIM,
                'gat_heads': GAT_HEADS,
                'gat_layers': GAT_LAYERS,
                'top_50_codes': TOP_50_CODES
            }
        }, MODELS_PATH / 'phase2_best.pt')
        print(f"   ‚úÖ Saved best model (F1: {best_f1:.4f})")

    print()

print(f"\n{'='*80}")
print(f"‚úÖ Training complete!")
print(f"   Best epoch: {best_epoch}")
print(f"   Best val F1: {best_f1:.4f}")
print(f"{'='*80}\n")

# Save history
with open(RESULTS_PATH / 'training_history.json', 'w') as f:
    json.dump(history, f, indent=2)

# ============================================================================
# FINAL TEST EVALUATION
# ============================================================================

print("="*80)
print("üìä FINAL TEST EVALUATION")
print("="*80)

checkpoint = torch.load(MODELS_PATH / 'phase2_best.pt', map_location=device, weights_only=False)
model.load_state_dict(checkpoint['model_state_dict'])
model.eval()

all_dx_preds, all_dx_labels = [], []
all_concept_preds, all_concept_labels = [], []

with torch.no_grad():
    for batch in tqdm(test_loader, desc="Testing"):
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        dx_labels = batch['labels'].to(device)
        concept_labels = batch['concept_labels'].to(device)

        if USE_AMP:
            with autocast():
                outputs = model(input_ids, attention_mask, concept_embeddings)
        else:
            outputs = model(input_ids, attention_mask, concept_embeddings)

        all_dx_preds.append(torch.sigmoid(outputs['logits']).cpu().numpy())
        all_dx_labels.append(dx_labels.cpu().numpy())
        all_concept_preds.append(outputs['concept_scores'].cpu().numpy())
        all_concept_labels.append(concept_labels.cpu().numpy())

all_dx_preds = np.vstack(all_dx_preds)
all_dx_labels = np.vstack(all_dx_labels)
all_concept_preds = np.vstack(all_concept_preds)
all_concept_labels = np.vstack(all_concept_labels)

dx_pred_binary = (all_dx_preds > 0.5).astype(int)
concept_pred_binary = (all_concept_preds > 0.5).astype(int)

macro_f1 = f1_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
micro_f1 = f1_score(all_dx_labels, dx_pred_binary, average='micro', zero_division=0)
macro_precision = precision_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)
macro_recall = recall_score(all_dx_labels, dx_pred_binary, average='macro', zero_division=0)

per_class_f1 = [
    f1_score(all_dx_labels[:, i], dx_pred_binary[:, i], zero_division=0)
    for i in range(NUM_LABELS)
]

concept_f1 = f1_score(all_concept_labels, concept_pred_binary, average='macro', zero_division=0)

print("\n" + "="*80)
print("üéâ SHIFAMIND v302 PHASE 2 - FINAL RESULTS")
print("="*80)

print("\nüéØ Diagnosis Performance (Fixed 0.5 threshold):")
print(f"   Macro F1:    {macro_f1:.4f}")
print(f"   Micro F1:    {micro_f1:.4f}")
print(f"   Precision:   {macro_precision:.4f}")
print(f"   Recall:      {macro_recall:.4f}")

print(f"\nüß† Concept Performance:")
print(f"   Concept F1:  {concept_f1:.4f}")

print(f"\nüìä Top-10 Best Performing Diagnoses:")
top_10_best = sorted(zip(TOP_50_CODES, per_class_f1), key=lambda x: x[1], reverse=True)[:10]
for rank, (code, f1) in enumerate(top_10_best, 1):
    count = top50_info['top_50_counts'].get(code, 0)
    print(f"   {rank}. {code}: F1={f1:.4f} (n={count:,})")

print(f"\n‚ö†Ô∏è  Note: This is with fixed 0.5 threshold!")
print(f"   Run threshold tuning next for ~2x improvement!")

# Save results
results = {
    'phase': 'ShifaMind v302 Phase 2 - GAT + UMLS (OPTIMIZED)',
    'timestamp': RUN_TIMESTAMP,
    'run_folder': str(RUN_PATH),
    'diagnosis_metrics': {
        'macro_f1': float(macro_f1),
        'micro_f1': float(micro_f1),
        'precision': float(macro_precision),
        'recall': float(macro_recall),
        'per_class_f1': {code: float(f1) for code, f1 in zip(TOP_50_CODES, per_class_f1)}
    },
    'concept_metrics': {
        'concept_f1': float(concept_f1),
        'num_concepts': NUM_CONCEPTS
    },
    'architecture': {
        'graph_construction': 'UMLS MRREL',
        'node_features': 'BioClinicalBERT embeddings',
        'gnn': 'GAT',
        'gat_heads': GAT_HEADS,
        'gat_layers': GAT_LAYERS
    },
    'optimizations': {
        'batch_size_train': TRAIN_BATCH_SIZE,
        'batch_size_val': VAL_BATCH_SIZE,
        'num_workers': NUM_WORKERS,
        'prefetch_factor': PREFETCH_FACTOR,
        'learning_rate': LEARNING_RATE,
        'fp16_precision': USE_AMP
    },
    'training_history': history
}

with open(RESULTS_PATH / 'results.json', 'w') as f:
    json.dump(results, f, indent=2)

per_label_df = pd.DataFrame({
    'icd_code': TOP_50_CODES,
    'f1_score': per_class_f1,
    'train_count': [top50_info['top_50_counts'].get(code, 0) for code in TOP_50_CODES]
})
per_label_df = per_label_df.sort_values('f1_score', ascending=False)
per_label_df.to_csv(RESULTS_PATH / 'per_label_f1.csv', index=False)

print(f"\nüíæ Results saved to: {RESULTS_PATH / 'results.json'}")
print(f"üíæ Per-label F1 saved to: {RESULTS_PATH / 'per_label_f1.csv'}")
print(f"üíæ Best model saved to: {MODELS_PATH / 'phase2_best.pt'}")

print("\n" + "="*80)
print("‚úÖ SHIFAMIND v302 PHASE 2 COMPLETE!")
print("="*80)

print(f"\nüìç Summary:")
print(f"   ‚úÖ GAT + UMLS knowledge graph")
print(f"   ‚úÖ MAXIMUM GPU optimization (batch_size={TRAIN_BATCH_SIZE}/{VAL_BATCH_SIZE})")
print(f"   ‚úÖ Transfer learning from Phase 1")
print(f"   ‚úÖ Macro F1: {macro_f1:.4f} (before threshold tuning)")
print(f"   ‚è±Ô∏è  Training time: {NUM_EPOCHS} epochs in ~10-15 mins")

print(f"\nüéØ NEXT STEP:")
print(f"   Run threshold tuning on this model for ~2x F1 improvement!")
print(f"   Expected after tuning: Macro F1 > 0.40")

print(f"\nüìÅ All artifacts saved to: {RUN_PATH}")
print("\nAlhamdulillah! ü§≤")
